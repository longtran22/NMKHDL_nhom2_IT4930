{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb9nvu1jBluG",
        "outputId": "b2adc448-a847-4e0d-9faa-8f10cd1c4460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os, math, random, argparse, itertools\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import WavLMModel, WavLMConfig, AutoConfig, AutoModel\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    classification_report,\n",
        ")\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import glob"
      ],
      "metadata": {
        "id": "KtJHB70S-VrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFncCOMnIMIy",
        "outputId": "c6c13a70-5794-4c16-8597-8bca5da7d5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'crema-d' dataset.\n",
            "Path to dataset files: /kaggle/input/crema-d\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"akaiinu/crema-d\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx0O2mJm6i5H"
      },
      "outputs": [],
      "source": [
        "audio_path = \"/root/.cache/kagglehub/datasets/akaiinu/crema-d/versions/1/cremad/AudioWAV\"\n",
        "files = glob.glob(os.path.join(audio_path, \"*.wav\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Utils\n",
        "# =========================\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# Ánh xạ nhãn cảm xúc sang số nguyên\n",
        "EMO_MAP = {\"ANG\":0, \"DIS\":1, \"FEA\":2, \"HAP\":3, \"NEU\":4, \"SAD\":5}\n",
        "# Ánh xạ ngược từ số nguyên sang nhãn cảm xúc\n",
        "IDX2EMO = {v:k for k,v in EMO_MAP.items()}\n",
        "\n",
        "def set_deterministic():\n",
        "    # Đặt seed để kết quả có thể tái lập\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def parse_label_from_filename(fname: str) -> int:\n",
        "    # Phân tích tên file để lấy nhãn cảm xúc\n",
        "    # Định dạng CREMA-D: ID_Sentence_Emotion_Intensity.wav\n",
        "    # Ví dụ: 1001_DFA_ANG_XX.wav\n",
        "    parts = os.path.basename(fname).split(\"_\")\n",
        "    emo = parts[2]\n",
        "    return EMO_MAP[emo] # Trả về số nguyên tương ứng với cảm xúc\n",
        "\n",
        "def compute_UA_WA(y_true, y_pred, n_classes=6):\n",
        "    # Tính Unweighted Accuracy (UA) và Weighted Accuracy (WA)\n",
        "    # UA: trung bình recall trên các lớp; WA: độ chính xác tổng thể\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(n_classes)))\n",
        "    per_class_acc = []\n",
        "    for c in range(n_classes):\n",
        "        denom = cm[c].sum()\n",
        "        per_class_acc.append((cm[c,c] / denom) if denom>0 else 0.0)\n",
        "    UA = float(np.mean(per_class_acc))\n",
        "    WA = float(np.trace(cm)) / float(np.sum(cm))\n",
        "    return UA, WA, cm\n"
      ],
      "metadata": {
        "id": "ftlI2cBq-onr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# Dataset\n",
        "# =========================\n",
        "class CREMADataset(Dataset):\n",
        "    # Lớp Dataset cho bộ dữ liệu CREMA-D\n",
        "    def __init__(self, data_root: str, split: str, sr: int = 16000, val_ratio: float = 0.1, test_ratio: float = 0.1):\n",
        "        assert split in [\"train\",\"val\",\"test\"]\n",
        "        self.sr = sr # Tốc độ lấy mẫu mục tiêu\n",
        "        # Lấy tất cả các file .wav trong thư mục data_root\n",
        "        all_files = [os.path.join(data_root, f) for f in os.listdir(data_root) if f.lower().endswith(\".wav\")]\n",
        "        all_files = sorted(all_files)\n",
        "        # Chia tập dữ liệu theo cảm xúc để đảm bảo phân bố đều (Stratified split)\n",
        "        emo_buckets = defaultdict(list)\n",
        "        for f in all_files:\n",
        "            try:\n",
        "                lab = parse_label_from_filename(f)\n",
        "                emo_buckets[lab].append(f)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        train_files, val_files, test_files = [], [], []\n",
        "        rng = random.Random(SEED)\n",
        "        for lab, lst in emo_buckets.items():\n",
        "            rng.shuffle(lst) # Xáo trộn file trong mỗi bucket cảm xúc\n",
        "            n = len(lst)\n",
        "            n_test = int(round(test_ratio*n))\n",
        "            n_val  = int(round(val_ratio*n))\n",
        "            # Chia file vào các tập train/val/test\n",
        "            test_files += lst[:n_test]\n",
        "            val_files  += lst[n_test:n_test+n_val]\n",
        "            train_files += lst[n_test+n_val:]\n",
        "\n",
        "        # Gán danh sách file cho tập dữ liệu hiện tại (train, val, hoặc test)\n",
        "        if split==\"train\": self.files = train_files\n",
        "        elif split==\"val\": self.files = val_files\n",
        "        else: self.files = test_files\n",
        "\n",
        "        # Bộ resampler nếu tốc độ lấy mẫu gốc khác mục tiêu\n",
        "        # self.resampler = torchaudio.transforms.Resample(orig_freq=44100, new_freq=sr)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Trả về số lượng file trong tập dữ liệu\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Lấy mẫu dữ liệu theo index\n",
        "        path = self.files[idx]\n",
        "        y = parse_label_from_filename(path) # Lấy nhãn cảm xúc\n",
        "        wav, sr = torchaudio.load(path) # Load file audio\n",
        "        wav = wav.mean(dim=0, keepdim=True)  # Chuyển sang mono\n",
        "        if sr != self.sr:\n",
        "            # CREMA-D gốc 44.1kHz, resample nếu cần\n",
        "            wav = torchaudio.functional.resample(wav, sr, self.sr)\n",
        "        wav = wav.squeeze(0)  # Bỏ chiều kênh nếu là mono [T]\n",
        "        # Chuẩn hóa năng lượng nhẹ về [-1, 1]\n",
        "        wav = wav / (wav.abs().max() + 1e-9)\n",
        "        return wav, y, path # Trả về waveform, nhãn và đường dẫn file\n",
        "\n",
        "def collate_batch(batch):\n",
        "    # Hàm collate để xử lý batch dữ liệu cho DataLoader\n",
        "    # Pad các waveform trong batch về cùng độ dài lớn nhất\n",
        "    wavs, labels, paths = zip(*batch)\n",
        "    lengths = [len(w) for w in wavs] # Độ dài gốc của từng waveform\n",
        "    maxlen = max(lengths) # Độ dài lớn nhất trong batch\n",
        "    padded = []\n",
        "    for w in wavs:\n",
        "        if len(w) < maxlen:\n",
        "            # Pad waveform nếu ngắn hơn maxlen\n",
        "            w = F.pad(w, (0, maxlen - len(w)))\n",
        "        padded.append(w.unsqueeze(0)) # Thêm chiều batch\n",
        "    audio = torch.cat(padded, dim=0)  # Nối các waveform đã pad thành một tensor [B, T]\n",
        "    labels = torch.tensor(labels, dtype=torch.long) # Chuyển nhãn thành tensor\n",
        "    return audio, labels, torch.tensor(lengths, dtype=torch.long), paths # Trả về batch\n"
      ],
      "metadata": {
        "id": "Qn8mKD8_-xQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# SL-WDEE Emotional Encoder\n",
        "# =========================\n",
        "class ContextualTransform(nn.Module):\n",
        "    \"\"\"\n",
        "    Biến đổi đặc trưng frame-by-frame thành đặc trưng có ngữ cảnh (từ t-L đến t+R).\n",
        "    Input:  [B, T, D] (Batch, Time, Dimension)\n",
        "    Output: [B, T, D*(L+R+1)]\n",
        "    \"\"\"\n",
        "    def __init__(self, left=5, right=5):\n",
        "        super().__init__()\n",
        "        self.l = left # Số frame ngữ cảnh bên trái\n",
        "        self.r = right # Số frame ngữ cảnh bên phải\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, D]\n",
        "        B, T, D = x.shape\n",
        "        pads = (self.l, self.r)  # Số lượng padding theo chiều thời gian T\n",
        "        # Pad tensor theo chiều thời gian bằng cách lặp lại giá trị ở biên (mode=\"replicate\")\n",
        "        x_pad = F.pad(x.transpose(1,2), pad=(self.l, self.r), mode=\"replicate\").transpose(1,2)  # [B, T+L+R, D]\n",
        "        ctx_list = []\n",
        "        # Trích xuất các dải frame ngữ cảnh\n",
        "        for offset in range(-self.l, self.r+1):\n",
        "            start = (self.l + offset)\n",
        "            end = start + T\n",
        "            ctx_list.append(x_pad[:, start:end, :])  # [B, T, D]\n",
        "        # Nối các dải ngữ cảnh lại theo chiều cuối cùng (dimension)\n",
        "        ctx = torch.cat(ctx_list, dim=-1)  # [B, T, D*(L+R+1)]\n",
        "        return ctx\n",
        "\n",
        "class EmotionalEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Mô-đun Emotional Encoder theo bài báo SL-WDEE:\n",
        "    Layer Normalization -> Contextual Transform -> Linear -> Sigmoid -> Linear -> Sigmoid.\n",
        "    Trả về đặc trưng theo từng frame (SL-WDEE_t) và đặc trưng mức utterance (pooling).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, hidden_dim=512, out_dim=256, left=5, right=5):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(in_dim) # Layer Normalization\n",
        "        self.ctx = ContextualTransform(left, right) # Biến đổi ngữ cảnh\n",
        "        self.fc1 = nn.Linear(in_dim*(left+right+1), hidden_dim) # Lớp Linear thứ nhất\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_dim) # Lớp Linear thứ hai\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, D] (đặc trưng từ WavLM)\n",
        "        x = self.norm(x) # Áp dụng Layer Normalization\n",
        "        x = self.ctx(x)                 # Áp dụng biến đổi ngữ cảnh [B, T, D*11]\n",
        "        x = torch.sigmoid(self.fc1(x))  # Lớp Linear 1 + Sigmoid [B, T, H]\n",
        "        x = torch.sigmoid(self.fc2(x))  # Lớp Linear 2 + Sigmoid [B, T, out]\n",
        "        # Pooling mức Utterance (trung bình cộng qua chiều thời gian)\n",
        "        wdee_utt = x.mean(dim=1)       # [B, out]\n",
        "        return x, wdee_utt  # Trả về đặc trưng frame-level và utterance-level\n"
      ],
      "metadata": {
        "id": "3PbaeKfZ-ydE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Classifier (utterance level)\n",
        "# =========================\n",
        "class MLPClassifier(nn.Module):\n",
        "    # Bộ phân loại MLP đơn giản cho đặc trưng mức utterance\n",
        "    def __init__(self, in_dim=256, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 256),     # Lớp Linear 1\n",
        "            nn.ReLU(inplace=True),      # Hàm kích hoạt ReLU\n",
        "            nn.Dropout(0.2),            # Dropout để chống overfitting\n",
        "            nn.Linear(256, 128),        # Lớp Linear 2\n",
        "            nn.ReLU(inplace=True),      # Hàm kích hoạt ReLU\n",
        "            nn.Dropout(0.2),            # Dropout\n",
        "            nn.Linear(128, num_classes) # Lớp Linear cuối cùng ra số lớp\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # x: [B, in_dim] (đặc trưng mức utterance)\n",
        "        return self.net(x) # Trả về logits\n"
      ],
      "metadata": {
        "id": "Z8fPYcyb_Atv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SER Model (WavLM -> SL-WDEE -> Classifier)\n",
        "# =========================\n",
        "class SER_WavLM_WDEE(nn.Module):\n",
        "    # Mô hình nhận dạng cảm xúc giọng nói kết hợp WavLM và SL-WDEE\n",
        "    def __init__(self, wavlm_name=\"microsoft/wavlm-base-plus\",\n",
        "                 wdee_hidden=512, wdee_out=256, freeze_wavlm=True):\n",
        "        super().__init__()\n",
        "        # Tải mô hình WavLM từ Hugging Face Transformers\n",
        "        self.wavlm = AutoModel.from_pretrained(wavlm_name)\n",
        "        hidden = self.wavlm.config.hidden_size # Kích thước đặc trưng đầu ra của WavLM (768)\n",
        "        # Khởi tạo Emotional Encoder\n",
        "        self.encoder = EmotionalEncoder(in_dim=hidden, hidden_dim=wdee_hidden, out_dim=wdee_out)\n",
        "        # Khởi tạo bộ phân loại MLP\n",
        "        self.cls = MLPClassifier(in_dim=wdee_out, num_classes=6)\n",
        "        # Tùy chọn đóng băng (freeze) các tham số của WavLM\n",
        "        if freeze_wavlm:\n",
        "            for p in self.wavlm.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _extract_wavlm_features(self, wav_batch, lengths):\n",
        "        # Trích xuất đặc trưng từ WavLM (không tính gradient)\n",
        "        # wav_batch: [B, T] float32, đã chuẩn hoá [-1,1]\n",
        "        B, T = wav_batch.shape\n",
        "        lengths = lengths.to(wav_batch.device)    #to device\n",
        "        # Tạo attention_mask: 1 cho phần có dữ liệu gốc, 0 cho phần padding\n",
        "        attention_mask = (torch.arange(T, device=wav_batch.device)[None, :] < lengths[:, None]).long()\n",
        "        # Chạy WavLM\n",
        "        outputs = self.wavlm(input_values=wav_batch, attention_mask=attention_mask, output_hidden_states=False)\n",
        "        feats = outputs.last_hidden_state  # Lấy đặc trưng từ lớp cuối cùng [B, T', D] (T' là số frame sau WavLM)\n",
        "        return feats\n",
        "\n",
        "\n",
        "    def forward(self, wav_batch, lengths):\n",
        "          # Chạy forward pass của toàn bộ mô hình\n",
        "          feats = self._extract_wavlm_features(wav_batch, lengths)   # Trích xuất đặc trưng WavLM [B,T',D]\n",
        "          per_frame_wdee, utt_wdee = self.encoder(feats)              # Chạy qua Emotional Encoder [B,T',E], [B,E]\n",
        "          logits = self.cls(utt_wdee)                                 # Chạy qua bộ phân loại [B,6]\n",
        "          return logits, utt_wdee # Trả về logits dự đoán cảm xúc và đặc trưng mức utterance WDEE\n"
      ],
      "metadata": {
        "id": "ajS23Vlz_F7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Training / Evaluation\n",
        "# =========================\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    # Lớp cấu hình cho quá trình huấn luyện\n",
        "    data_root: str\n",
        "    batch_size: int = 8\n",
        "    epochs: int = 20\n",
        "    lr: float = 2e-4\n",
        "    freeze_wavlm: bool = True\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    wavlm_name: str = \"microsoft/wavlm-base-plus\"\n",
        "    wdee_hidden: int = 512\n",
        "    wdee_out: int = 256\n",
        "    sr: int = 16000\n",
        "    val_ratio: float = 0.1\n",
        "    test_ratio: float = 0.1\n",
        "    grad_clip: float = 1.0\n",
        "    mixed_precision: bool = True # Sử dụng mixed precision training để tăng tốc (nếu có GPU)\n",
        "\n",
        "def train_one_epoch(model, loader, optim, scaler, cfg):\n",
        "    # Hàm huấn luyện một epoch\n",
        "    model.train() # Đặt model ở chế độ train\n",
        "    total_loss, total, correct = 0.0, 0, 0\n",
        "    for wav, y, lengths, _ in tqdm(loader, desc=\"Train\", leave=False):\n",
        "        wav, y = wav.to(cfg.device), y.to(cfg.device) # Chuyển dữ liệu lên device\n",
        "        optim.zero_grad(set_to_none=True) # Reset gradient\n",
        "        if cfg.mixed_precision:\n",
        "            # Sử dụng mixed precision nếu bật và có GPU\n",
        "            with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
        "                logits, _ = model(wav, lengths) # Forward pass\n",
        "                loss = F.cross_entropy(logits, y) # Tính loss (Cross-Entropy)\n",
        "            scaler.scale(loss).backward() # Scale loss và backward\n",
        "            scaler.unscale_(optim) # Unscale gradient trước khi clip\n",
        "            if cfg.grad_clip is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip) # Clip gradient\n",
        "            scaler.step(optim) # Cập nhật tham số\n",
        "            scaler.update() # Cập nhật scaler\n",
        "        else:\n",
        "            # Huấn luyện thông thường (full precision)\n",
        "            logits, _ = model(wav, lengths)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            if cfg.grad_clip is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "            optim.step()\n",
        "\n",
        "        total_loss += float(loss.item()) * len(y) # Cộng dồn loss\n",
        "        pred = logits.argmax(dim=1) # Lấy dự đoán\n",
        "        correct += int((pred==y).sum().item()) # Đếm số lượng dự đoán đúng\n",
        "        total += len(y) # Tổng số mẫu trong batch\n",
        "    return total_loss/total, correct/total # Trả về loss và accuracy trung bình epoch\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, cfg):\n",
        "    # Hàm đánh giá mô hình (không tính gradient)\n",
        "    model.eval()\n",
        "    total_loss, total, correct = 0.0, 0, 0\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for wav, y, lengths, _ in tqdm(loader, desc=\"Eval\", leave=False):\n",
        "        wav, y = wav.to(cfg.device), y.to(cfg.device)\n",
        "        logits, _ = model(wav, lengths)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        total_loss += float(loss.item()) * len(y)\n",
        "\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += int((pred == y).sum().item())\n",
        "        total += len(y)\n",
        "\n",
        "        y_true += y.detach().cpu().tolist()\n",
        "        y_pred += pred.detach().cpu().tolist()\n",
        "\n",
        "    # UA, WA, Confusion Matrix\n",
        "    UA, WA, cm = compute_UA_WA(y_true, y_pred, n_classes=6)\n",
        "\n",
        "    # Precision / Recall / F1\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    weighted_f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    macro_precision = precision_score(y_true, y_pred, average=\"macro\")\n",
        "    weighted_precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    macro_recall = recall_score(y_true, y_pred, average=\"macro\")\n",
        "    weighted_recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    # (tuỳ chọn) in luôn classification report dạng bảng\n",
        "    cls_report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[IDX2EMO[i] for i in range(6)],\n",
        "        digits=4\n",
        "    )\n",
        "\n",
        "    # Có thể in ra trong lúc - (debug)\n",
        "    # print(cls_report)\n",
        "\n",
        "    # Trả thêm các metric mới\n",
        "    return (\n",
        "        total_loss / total,\n",
        "        correct / total,\n",
        "        UA,\n",
        "        WA,\n",
        "        cm,\n",
        "        macro_f1,\n",
        "        weighted_f1,\n",
        "        macro_precision,\n",
        "        weighted_precision,\n",
        "        macro_recall,\n",
        "        weighted_recall,\n",
        "        cls_report,\n",
        "    )"
      ],
      "metadata": {
        "id": "7JgAtIi0_O9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Origin \"\"\"\n",
        "def main():\n",
        "    # Hàm chính để chạy huấn luyện và đánh giá\n",
        "    set_deterministic() # Đặt seed\n",
        "    cfg = TrainConfig(\n",
        "        data_root=\"/kaggle/input/crema-d/cremad/AudioWAV\", # Đường dẫn đến thư mục audio\n",
        "        epochs=20,\n",
        "        batch_size=8,\n",
        "        lr=2e-4,\n",
        "        freeze_wavlm=True # Đóng băng WavLM ở giai đoạn đầu\n",
        "    )\n",
        "    print(cfg)\n",
        "\n",
        "    # Khởi tạo Dataset cho train, val, test\n",
        "    train_ds = CREMADataset(cfg.data_root, \"train\", sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "    val_ds   = CREMADataset(cfg.data_root, \"val\",   sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "    test_ds  = CREMADataset(cfg.data_root, \"test\",  sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "\n",
        "    # Khởi tạo DataLoader\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "\n",
        "    # Khởi tạo mô hình\n",
        "    model = SER_WavLM_WDEE(\n",
        "        wavlm_name=cfg.wavlm_name,\n",
        "        wdee_hidden=cfg.wdee_hidden,\n",
        "        wdee_out=cfg.wdee_out,\n",
        "        freeze_wavlm=cfg.freeze_wavlm\n",
        "    ).to(cfg.device) # Chuyển model lên device\n",
        "\n",
        "    # Khởi tạo optimizer và scaler (cho mixed precision)\n",
        "    optim = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.lr)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(cfg.device.startswith(\"cuda\") and cfg.mixed_precision))\n",
        "\n",
        "    best_val_ua, best_state = -1.0, None\n",
        "    # Vòng lặp huấn luyện qua các epoch\n",
        "    for epoch in range(1, cfg.epochs+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optim, scaler, cfg) # Huấn luyện 1 epoch\n",
        "        (\n",
        "          val_loss,\n",
        "          val_acc,\n",
        "          val_UA,\n",
        "          val_WA,\n",
        "          _,\n",
        "          val_f1_macro,\n",
        "          val_f1_weighted,\n",
        "          val_prec_macro,\n",
        "          val_prec_weighted,\n",
        "          val_rec_macro,\n",
        "          val_rec_weighted,\n",
        "          _\n",
        "      ) = evaluate(model, val_loader, cfg)\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch:02d}] \"\n",
        "            f\"Train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "            f\"Val loss {val_loss:.4f} acc {val_acc:.4f} \"\n",
        "            f\"UA {val_UA:.4f} WA {val_WA:.4f} \"\n",
        "            f\"F1(macro) {val_f1_macro:.4f} F1(weighted) {val_f1_weighted:.4f}\"\n",
        "        )\n",
        "        # Lưu trạng thái mô hình nếu đạt UA tốt nhất trên tập validation\n",
        "        if val_UA > best_val_ua:\n",
        "            best_val_ua = val_UA\n",
        "            best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
        "\n",
        "    # Load lại trạng thái mô hình tốt nhất từ validation\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k:v.to(cfg.device) for k,v in best_state.items()})\n",
        "\n",
        "    # Đánh giá cuối cùng trên tập test\n",
        "    (\n",
        "          te_loss,\n",
        "          te_acc,\n",
        "          te_UA,\n",
        "          te_WA,\n",
        "          _,\n",
        "          te_f1_macro,\n",
        "          te_f1_weighted,\n",
        "          te_prec_macro,\n",
        "          te_prec_weighted,\n",
        "          te_rec_macro,\n",
        "          te_rec_weighted,\n",
        "          _\n",
        "      ) = evaluate(model, test_loader, cfg)\n",
        "    print(\"\\n=== TEST RESULTS (CREMA-D) ===\")\n",
        "    print(f\"Train loss {te_loss:.4f} acc {te_acc:.4f} | \"\n",
        "            f\"Val loss {val_loss:.4f} acc {val_acc:.4f} \"\n",
        "            f\"UA {te_UA:.4f} WA {te_WA:.4f} \"\n",
        "            f\"F1(macro) {te_f1_macro:.4f} F1(weighted) {te_f1_weighted:.4f}\")\n",
        "    # # In ra confusion matrix có nhãn\n",
        "    # df_cm = pd.DataFrame(cm, index=[IDX2EMO[i] for i in range(6)], columns=[IDX2EMO[i] for i in range(6)])\n",
        "    # print(\"\\nConfusion matrix:\")\n",
        "    # print(df_cm)\n",
        "\n"
      ],
      "metadata": {
        "id": "kfZMHskA_Ygt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main() # Chạy hàm main khi script được thực thi trực tiếp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSW2kGGrJXrt",
        "outputId": "9fd11ad2-1d80-4e6e-8ee3-883daedf49c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainConfig(data_root='/kaggle/input/crema-d/cremad/AudioWAV', batch_size=8, epochs=20, lr=0.0002, freeze_wavlm=True, device='cuda', wavlm_name='microsoft/wavlm-base-plus', wdee_hidden=512, wdee_out=256, sr=16000, val_ratio=0.1, test_ratio=0.1, grad_clip=1.0, mixed_precision=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-1384558477.py:34: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(cfg.device.startswith(\"cuda\") and cfg.mixed_precision))\n",
            "Train:   0%|          | 0/745 [00:00<?, ?it/s]/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] Train loss 1.5683 acc 0.3371 | Val loss 1.5021 acc 0.3441 UA 0.3418 WA 0.3441 F1(macro) 0.2764 F1(weighted) 0.2784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 02] Train loss 1.4128 acc 0.4167 | Val loss 1.4205 acc 0.4140 UA 0.4111 WA 0.4140 F1(macro) 0.3577 F1(weighted) 0.3599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 03] Train loss 1.2804 acc 0.4899 | Val loss 1.2410 acc 0.5175 UA 0.5282 WA 0.5175 F1(macro) 0.4780 F1(weighted) 0.4756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 04] Train loss 1.1326 acc 0.5590 | Val loss 1.0939 acc 0.5726 UA 0.5783 WA 0.5726 F1(macro) 0.5713 F1(weighted) 0.5672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 05] Train loss 1.0730 acc 0.5858 | Val loss 1.0442 acc 0.5524 UA 0.5569 WA 0.5524 F1(macro) 0.5600 F1(weighted) 0.5553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 06] Train loss 1.0120 acc 0.6087 | Val loss 1.1542 acc 0.5914 UA 0.5993 WA 0.5914 F1(macro) 0.5666 F1(weighted) 0.5626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 07] Train loss 0.9880 acc 0.6229 | Val loss 0.9671 acc 0.6196 UA 0.6254 WA 0.6196 F1(macro) 0.6135 F1(weighted) 0.6099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 08] Train loss 0.9552 acc 0.6340 | Val loss 0.9515 acc 0.6290 UA 0.6337 WA 0.6290 F1(macro) 0.6204 F1(weighted) 0.6169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 09] Train loss 0.9491 acc 0.6460 | Val loss 0.9515 acc 0.6358 UA 0.6409 WA 0.6358 F1(macro) 0.6254 F1(weighted) 0.6217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Train loss 0.9108 acc 0.6612 | Val loss 1.0189 acc 0.6223 UA 0.6267 WA 0.6223 F1(macro) 0.6104 F1(weighted) 0.6066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 11] Train loss 0.9102 acc 0.6560 | Val loss 1.0751 acc 0.6183 UA 0.6256 WA 0.6183 F1(macro) 0.5943 F1(weighted) 0.5890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 12] Train loss 0.8955 acc 0.6648 | Val loss 0.9405 acc 0.6425 UA 0.6470 WA 0.6425 F1(macro) 0.6457 F1(weighted) 0.6426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 13] Train loss 0.8727 acc 0.6725 | Val loss 0.9518 acc 0.6519 UA 0.6588 WA 0.6519 F1(macro) 0.6424 F1(weighted) 0.6395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 14] Train loss 0.8534 acc 0.6822 | Val loss 0.9264 acc 0.6559 UA 0.6632 WA 0.6559 F1(macro) 0.6449 F1(weighted) 0.6419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 15] Train loss 0.8393 acc 0.6913 | Val loss 1.0361 acc 0.6116 UA 0.6177 WA 0.6116 F1(macro) 0.5954 F1(weighted) 0.5919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 16] Train loss 0.8125 acc 0.6990 | Val loss 0.8904 acc 0.6680 UA 0.6722 WA 0.6680 F1(macro) 0.6652 F1(weighted) 0.6613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 17] Train loss 0.8055 acc 0.6995 | Val loss 0.9016 acc 0.6734 UA 0.6768 WA 0.6734 F1(macro) 0.6699 F1(weighted) 0.6670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 18] Train loss 0.7962 acc 0.7071 | Val loss 0.8695 acc 0.6720 UA 0.6776 WA 0.6720 F1(macro) 0.6670 F1(weighted) 0.6642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 19] Train loss 0.7591 acc 0.7210 | Val loss 0.8419 acc 0.6828 UA 0.6864 WA 0.6828 F1(macro) 0.6852 F1(weighted) 0.6819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20] Train loss 0.7660 acc 0.7151 | Val loss 0.9208 acc 0.6868 UA 0.6916 WA 0.6868 F1(macro) 0.6780 F1(weighted) 0.6749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST RESULTS (CREMA-D) ===\n",
            "Train loss 0.8810 acc 0.6640 | Val loss 0.9208 acc 0.6868 UA 0.6689 WA 0.6640 F1(macro) 0.6558 F1(weighted) 0.6527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Finetune wavlm with diff optimize for wavlm and encoder/classifier\"\"\"\n",
        "def main():\n",
        "    # Hàm chính để chạy huấn luyện và đánh giá\n",
        "    set_deterministic() # Đặt seed\n",
        "    cfg = TrainConfig(\n",
        "        data_root=audio_path, # Đường dẫn đến thư mục audio\n",
        "        epochs=20,\n",
        "        batch_size=8,\n",
        "        lr=2e-4,\n",
        "        freeze_wavlm=True # Đóng băng WavLM ở giai đoạn đầu\n",
        "    )\n",
        "    print(cfg)\n",
        "\n",
        "    # Khởi tạo Dataset cho train, val, test\n",
        "    train_ds = CREMADataset(cfg.data_root, \"train\", sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "    val_ds   = CREMADataset(cfg.data_root, \"val\",   sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "    test_ds  = CREMADataset(cfg.data_root, \"test\",  sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "\n",
        "    # Khởi tạo DataLoader\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "\n",
        "    # Khởi tạo mô hình\n",
        "    model = SER_WavLM_WDEE(\n",
        "        wavlm_name=cfg.wavlm_name,\n",
        "        wdee_hidden=cfg.wdee_hidden,\n",
        "        wdee_out=cfg.wdee_out,\n",
        "        freeze_wavlm=cfg.freeze_wavlm\n",
        "    ).to(cfg.device) # Chuyển model lên device\n",
        "\n",
        "    # Khởi tạo optimizer và scaler (cho mixed precision)\n",
        "    optim = torch.optim.AdamW([\n",
        "    {'params': model.wavlm.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.encoder.parameters(), 'lr': 1e-4},\n",
        "    {'params': model.cls.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=1e-4)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(cfg.device.startswith(\"cuda\") and cfg.mixed_precision))\n",
        "\n",
        "    best_val_ua, best_state = -1.0, None\n",
        "    # Vòng lặp huấn luyện qua các epoch\n",
        "    for epoch in range(1, cfg.epochs+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optim, scaler, cfg) # Huấn luyện 1 epoch\n",
        "        (\n",
        "          val_loss,\n",
        "          val_acc,\n",
        "          val_UA,\n",
        "          val_WA,\n",
        "          _,\n",
        "          val_f1_macro,\n",
        "          val_f1_weighted,\n",
        "          val_prec_macro,\n",
        "          val_prec_weighted,\n",
        "          val_rec_macro,\n",
        "          val_rec_weighted,\n",
        "          _\n",
        "      ) = evaluate(model, val_loader, cfg)\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch:02d}] \"\n",
        "            f\"Train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "            f\"Val loss {val_loss:.4f} acc {val_acc:.4f} \"\n",
        "            f\"UA {val_UA:.4f} WA {val_WA:.4f} \"\n",
        "            f\"F1(macro) {val_f1_macro:.4f} F1(weighted) {val_f1_weighted:.4f}\"\n",
        "        )\n",
        "        # Lưu trạng thái mô hình nếu đạt UA tốt nhất trên tập validation\n",
        "        if val_UA > best_val_ua:\n",
        "            best_val_ua = val_UA\n",
        "            best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
        "\n",
        "    # Load lại trạng thái mô hình tốt nhất từ validation\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k:v.to(cfg.device) for k,v in best_state.items()})\n",
        "\n",
        "    # Đánh giá cuối cùng trên tập test\n",
        "    (\n",
        "          te_loss,\n",
        "          te_acc,\n",
        "          te_UA,\n",
        "          te_WA,\n",
        "          _,\n",
        "          te_f1_macro,\n",
        "          te_f1_weighted,\n",
        "          te_prec_macro,\n",
        "          te_prec_weighted,\n",
        "          te_rec_macro,\n",
        "          te_rec_weighted,\n",
        "          _\n",
        "      ) = evaluate(model, test_loader, cfg)\n",
        "    print(\"\\n=== TEST RESULTS (CREMA-D) ===\")\n",
        "    print(f\"Train loss {te_loss:.4f} acc {te_acc:.4f} | \"\n",
        "            f\"Val loss {val_loss:.4f} acc {val_acc:.4f} \"\n",
        "            f\"UA {te_UA:.4f} WA {te_WA:.4f} \"\n",
        "            f\"F1(macro) {te_f1_macro:.4f} F1(weighted) {te_f1_weighted:.4f}\")\n",
        "    # # In ra confusion matrix có nhãn\n",
        "    # df_cm = pd.DataFrame(cm, index=[IDX2EMO[i] for i in range(6)], columns=[IDX2EMO[i] for i in range(6)])\n",
        "    # print(\"\\nConfusion matrix:\")\n",
        "    # print(df_cm)\n",
        "\n"
      ],
      "metadata": {
        "id": "EgbiQ7JmAmac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main() # Chạy hàm main khi script được thực thi trực tiếp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ARqvu_Ak4l",
        "outputId": "e00a83f8-a04c-40e0-d922-70354a961460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainConfig(data_root='/root/.cache/kagglehub/datasets/akaiinu/crema-d/versions/1/cremad/AudioWAV', batch_size=8, epochs=20, lr=0.0002, freeze_wavlm=True, device='cuda', wavlm_name='microsoft/wavlm-base-plus', wdee_hidden=512, wdee_out=256, sr=16000, val_ratio=0.1, test_ratio=0.1, grad_clip=1.0, mixed_precision=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2268076309.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(cfg.device.startswith(\"cuda\") and cfg.mixed_precision))\n",
            "Train:   0%|          | 0/745 [00:00<?, ?it/s]/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] Train loss 1.5989 acc 0.3275 | Val loss 1.4571 acc 0.4126 UA 0.4029 WA 0.4126 F1(macro) 0.3286 F1(weighted) 0.3366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 02] Train loss 1.4383 acc 0.4043 | Val loss 1.4020 acc 0.4382 UA 0.4395 WA 0.4382 F1(macro) 0.3587 F1(weighted) 0.3576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 03] Train loss 1.3895 acc 0.4259 | Val loss 1.3437 acc 0.4637 UA 0.4593 WA 0.4637 F1(macro) 0.4148 F1(weighted) 0.4174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 04] Train loss 1.3331 acc 0.4599 | Val loss 1.3340 acc 0.4637 UA 0.4612 WA 0.4637 F1(macro) 0.4318 F1(weighted) 0.4340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 05] Train loss 1.2742 acc 0.4881 | Val loss 1.2221 acc 0.5215 UA 0.5231 WA 0.5215 F1(macro) 0.4887 F1(weighted) 0.4891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 06] Train loss 1.1832 acc 0.5366 | Val loss 1.1592 acc 0.5645 UA 0.5690 WA 0.5645 F1(macro) 0.5396 F1(weighted) 0.5381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 07] Train loss 1.1055 acc 0.5715 | Val loss 1.2242 acc 0.5296 UA 0.5357 WA 0.5296 F1(macro) 0.5070 F1(weighted) 0.5051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 08] Train loss 1.0535 acc 0.5972 | Val loss 1.0811 acc 0.6008 UA 0.6089 WA 0.6008 F1(macro) 0.5826 F1(weighted) 0.5811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 09] Train loss 1.0355 acc 0.6045 | Val loss 1.0509 acc 0.5927 UA 0.5941 WA 0.5927 F1(macro) 0.5883 F1(weighted) 0.5855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Train loss 0.9961 acc 0.6234 | Val loss 1.0229 acc 0.6169 UA 0.6234 WA 0.6169 F1(macro) 0.6063 F1(weighted) 0.6028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 11] Train loss 0.9847 acc 0.6297 | Val loss 1.0100 acc 0.6048 UA 0.6111 WA 0.6048 F1(macro) 0.5941 F1(weighted) 0.5909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 12] Train loss 0.9662 acc 0.6349 | Val loss 1.0487 acc 0.6102 UA 0.6136 WA 0.6102 F1(macro) 0.5977 F1(weighted) 0.5945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 13] Train loss 0.9463 acc 0.6384 | Val loss 1.0718 acc 0.5981 UA 0.6065 WA 0.5981 F1(macro) 0.5792 F1(weighted) 0.5765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 14] Train loss 0.9428 acc 0.6443 | Val loss 0.9972 acc 0.6116 UA 0.6166 WA 0.6116 F1(macro) 0.6029 F1(weighted) 0.5998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 15] Train loss 0.9175 acc 0.6544 | Val loss 0.9401 acc 0.6438 UA 0.6501 WA 0.6438 F1(macro) 0.6418 F1(weighted) 0.6384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 16] Train loss 0.9199 acc 0.6545 | Val loss 0.9602 acc 0.6438 UA 0.6509 WA 0.6438 F1(macro) 0.6333 F1(weighted) 0.6301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 17] Train loss 0.9156 acc 0.6577 | Val loss 0.9167 acc 0.6599 UA 0.6656 WA 0.6599 F1(macro) 0.6549 F1(weighted) 0.6522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 18] Train loss 0.9062 acc 0.6607 | Val loss 0.9767 acc 0.6371 UA 0.6426 WA 0.6371 F1(macro) 0.6292 F1(weighted) 0.6260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 19] Train loss 0.8857 acc 0.6722 | Val loss 0.9307 acc 0.6492 UA 0.6551 WA 0.6492 F1(macro) 0.6443 F1(weighted) 0.6398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-343210823.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20] Train loss 0.8779 acc 0.6701 | Val loss 0.9290 acc 0.6640 UA 0.6708 WA 0.6640 F1(macro) 0.6557 F1(weighted) 0.6523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6044: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST RESULTS (CREMA-D) ===\n",
            "Train loss 0.8738 acc 0.6815 | Val loss 0.9290 acc 0.6640 UA 0.6864 WA 0.6815 F1(macro) 0.6776 F1(weighted) 0.6752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Origin:\n",
        "Train loss 0.8810 acc 0.6640 | Val loss 0.9208 acc 0.6868 UA 0.6689 WA 0.6640 F1(macro) 0.6558 F1(weighted) 0.6527\n",
        "\n",
        "Finetune wavlm with diff optimize for wavlm and encoder/classifier:\n",
        "Train loss 0.8738 acc 0.6815 | Val loss 0.9290 acc 0.6640 UA 0.6864 WA 0.6815 F1(macro) 0.6776 F1(weighted) 0.6752\n"
      ],
      "metadata": {
        "id": "AHFK0BNAQbAX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VQddcrMrQfMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSM2VaiT6Q1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d28c373f-34bb-48e6-c054-3cde7d79878a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TrainConfig(data_root='/kaggle/input/crema-d/cremad/AudioWAV', batch_size=8, epochs=20, lr=0.0002, freeze_wavlm=True, device='cuda', wavlm_name='microsoft/wavlm-base-plus', wdee_hidden=512, wdee_out=256, sr=16000, val_ratio=0.1, test_ratio=0.1, grad_clip=1.0, mixed_precision=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at microsoft/wavlm-base-plus were not used when initializing WavLMModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing WavLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing WavLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of WavLMModel were not initialized from the model checkpoint at microsoft/wavlm-base-plus and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1291959601.py:394: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(cfg.device.startswith(\"cuda\") and cfg.mixed_precision))\n",
            "Train:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] Train loss 1.5487 acc 0.3534 | Val loss 1.4426 acc 0.4086 UA 0.4115 WA 0.4086 F1(macro) 0.3375 F1(weighted) 0.3373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 02] Train loss 1.3898 acc 0.4365 | Val loss 1.3005 acc 0.4785 UA 0.4789 WA 0.4785 F1(macro) 0.4343 F1(weighted) 0.4345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 03] Train loss 1.2398 acc 0.5091 | Val loss 1.2531 acc 0.5067 UA 0.5069 WA 0.5067 F1(macro) 0.4858 F1(weighted) 0.4840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 04] Train loss 1.1177 acc 0.5700 | Val loss 1.0815 acc 0.5712 UA 0.5788 WA 0.5712 F1(macro) 0.5599 F1(weighted) 0.5576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 05] Train loss 1.0559 acc 0.5979 | Val loss 1.2270 acc 0.5417 UA 0.5482 WA 0.5417 F1(macro) 0.5196 F1(weighted) 0.5152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 06] Train loss 1.0186 acc 0.6065 | Val loss 1.0771 acc 0.5954 UA 0.6048 WA 0.5954 F1(macro) 0.5778 F1(weighted) 0.5759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 07] Train loss 0.9850 acc 0.6261 | Val loss 1.0966 acc 0.5927 UA 0.6019 WA 0.5927 F1(macro) 0.5710 F1(weighted) 0.5681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 08] Train loss 0.9742 acc 0.6352 | Val loss 1.1124 acc 0.5874 UA 0.5960 WA 0.5874 F1(macro) 0.5653 F1(weighted) 0.5617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 09] Train loss 0.9457 acc 0.6443 | Val loss 0.9954 acc 0.6277 UA 0.6350 WA 0.6277 F1(macro) 0.6139 F1(weighted) 0.6101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Train loss 0.9375 acc 0.6528 | Val loss 0.9735 acc 0.6358 UA 0.6435 WA 0.6358 F1(macro) 0.6229 F1(weighted) 0.6203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 11] Train loss 0.9119 acc 0.6604 | Val loss 0.9391 acc 0.6586 UA 0.6662 WA 0.6586 F1(macro) 0.6491 F1(weighted) 0.6465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 12] Train loss 0.8863 acc 0.6680 | Val loss 0.8919 acc 0.6734 UA 0.6783 WA 0.6734 F1(macro) 0.6745 F1(weighted) 0.6706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 13] Train loss 0.8722 acc 0.6696 | Val loss 0.8813 acc 0.6815 UA 0.6872 WA 0.6815 F1(macro) 0.6811 F1(weighted) 0.6785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 14] Train loss 0.8451 acc 0.6853 | Val loss 0.9574 acc 0.6505 UA 0.6573 WA 0.6505 F1(macro) 0.6418 F1(weighted) 0.6397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 15] Train loss 0.8425 acc 0.6935 | Val loss 0.9218 acc 0.6411 UA 0.6446 WA 0.6411 F1(macro) 0.6344 F1(weighted) 0.6318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 16] Train loss 0.8168 acc 0.6980 | Val loss 0.9202 acc 0.6599 UA 0.6636 WA 0.6599 F1(macro) 0.6636 F1(weighted) 0.6598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 17] Train loss 0.8017 acc 0.7037 | Val loss 0.9078 acc 0.6613 UA 0.6658 WA 0.6613 F1(macro) 0.6567 F1(weighted) 0.6533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 18] Train loss 0.7978 acc 0.7031 | Val loss 0.9461 acc 0.6680 UA 0.6743 WA 0.6680 F1(macro) 0.6598 F1(weighted) 0.6565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 19] Train loss 0.7704 acc 0.7167 | Val loss 0.9670 acc 0.6667 UA 0.6741 WA 0.6667 F1(macro) 0.6565 F1(weighted) 0.6554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/745 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/tmp/ipython-input-1291959601.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Eval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20] Train loss 0.7772 acc 0.7158 | Val loss 0.8192 acc 0.7003 UA 0.7050 WA 0.7003 F1(macro) 0.6968 F1(weighted) 0.6940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEval:   0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "                                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST RESULTS (CREMA-D) ===\n",
            "Train loss 0.7742 acc 0.7137 | Val loss 0.8192 acc 0.7003 UA 0.7172 WA 0.7137 F1(macro) 0.7114 F1(weighted) 0.7098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1291959601.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Chạy hàm main khi script được thực thi trực tiếp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1291959601.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    450\u001b[0m             f\"F1(macro) {te_f1_macro:.4f} F1(weighted) {te_f1_weighted:.4f}\")\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# In ra confusion matrix có nhãn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDX2EMO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIDX2EMO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nConfusion matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Utils\n",
        "# =========================\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# Ánh xạ nhãn cảm xúc sang số nguyên\n",
        "EMO_MAP = {\"ANG\":0, \"DIS\":1, \"FEA\":2, \"HAP\":3, \"NEU\":4, \"SAD\":5}\n",
        "# Ánh xạ ngược từ số nguyên sang nhãn cảm xúc\n",
        "IDX2EMO = {v:k for k,v in EMO_MAP.items()}\n",
        "\n",
        "def set_deterministic():\n",
        "    # Đặt seed để kết quả có thể tái lập\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def parse_label_from_filename(fname: str) -> int:\n",
        "    # Phân tích tên file để lấy nhãn cảm xúc\n",
        "    # Định dạng CREMA-D: ID_Sentence_Emotion_Intensity.wav\n",
        "    # Ví dụ: 1001_DFA_ANG_XX.wav\n",
        "    parts = os.path.basename(fname).split(\"_\")\n",
        "    emo = parts[2]\n",
        "    return EMO_MAP[emo] # Trả về số nguyên tương ứng với cảm xúc\n",
        "\n",
        "def compute_UA_WA(y_true, y_pred, n_classes=6):\n",
        "    # Tính Unweighted Accuracy (UA) và Weighted Accuracy (WA)\n",
        "    # UA: trung bình recall trên các lớp; WA: độ chính xác tổng thể\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(n_classes)))\n",
        "    per_class_acc = []\n",
        "    for c in range(n_classes):\n",
        "        denom = cm[c].sum()\n",
        "        per_class_acc.append((cm[c,c] / denom) if denom>0 else 0.0)\n",
        "    UA = float(np.mean(per_class_acc))\n",
        "    WA = float(np.trace(cm)) / float(np.sum(cm))\n",
        "    return UA, WA, cm\n",
        "\n",
        "# =========================\n",
        "# Dataset\n",
        "# =========================\n",
        "class CREMADataset(Dataset):\n",
        "    # Lớp Dataset cho bộ dữ liệu CREMA-D\n",
        "    def __init__(self, data_root: str, split: str, sr: int = 16000, val_ratio: float = 0.1, test_ratio: float = 0.1):\n",
        "        assert split in [\"train\",\"val\",\"test\"]\n",
        "        self.sr = sr # Tốc độ lấy mẫu mục tiêu\n",
        "        # Lấy tất cả các file .wav trong thư mục data_root\n",
        "        all_files = [os.path.join(data_root, f) for f in os.listdir(data_root) if f.lower().endswith(\".wav\")]\n",
        "        all_files = sorted(all_files)\n",
        "        # Chia tập dữ liệu theo cảm xúc để đảm bảo phân bố đều (Stratified split)\n",
        "        emo_buckets = defaultdict(list)\n",
        "        for f in all_files:\n",
        "            try:\n",
        "                lab = parse_label_from_filename(f)\n",
        "                emo_buckets[lab].append(f)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        train_files, val_files, test_files = [], [], []\n",
        "        rng = random.Random(SEED)\n",
        "        for lab, lst in emo_buckets.items():\n",
        "            rng.shuffle(lst) # Xáo trộn file trong mỗi bucket cảm xúc\n",
        "            n = len(lst)\n",
        "            n_test = int(round(test_ratio*n))\n",
        "            n_val  = int(round(val_ratio*n))\n",
        "            # Chia file vào các tập train/val/test\n",
        "            test_files += lst[:n_test]\n",
        "            val_files  += lst[n_test:n_test+n_val]\n",
        "            train_files += lst[n_test+n_val:]\n",
        "\n",
        "        # Gán danh sách file cho tập dữ liệu hiện tại (train, val, hoặc test)\n",
        "        if split==\"train\": self.files = train_files\n",
        "        elif split==\"val\": self.files = val_files\n",
        "        else: self.files = test_files\n",
        "\n",
        "        # Bộ resampler nếu tốc độ lấy mẫu gốc khác mục tiêu\n",
        "        self.resampler = torchaudio.transforms.Resample(orig_freq=44100, new_freq=sr)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Trả về số lượng file trong tập dữ liệu\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Lấy mẫu dữ liệu theo index\n",
        "        path = self.files[idx]\n",
        "        y = parse_label_from_filename(path) # Lấy nhãn cảm xúc\n",
        "        wav, sr = torchaudio.load(path) # Load file audio\n",
        "        wav = wav.mean(dim=0, keepdim=True)  # Chuyển sang mono\n",
        "        if sr != self.sr:\n",
        "            # CREMA-D gốc 44.1kHz, resample nếu cần\n",
        "            wav = torchaudio.functional.resample(wav, sr, self.sr)\n",
        "        wav = wav.squeeze(0)  # Bỏ chiều kênh nếu là mono [T]\n",
        "        # Chuẩn hóa năng lượng nhẹ về [-1, 1]\n",
        "        wav = wav / (wav.abs().max() + 1e-9)\n",
        "        return wav, y, path # Trả về waveform, nhãn và đường dẫn file\n",
        "\n",
        "def collate_batch(batch):\n",
        "    # Hàm collate để xử lý batch dữ liệu cho DataLoader\n",
        "    # Pad các waveform trong batch về cùng độ dài lớn nhất\n",
        "    wavs, labels, paths = zip(*batch)\n",
        "    lengths = [len(w) for w in wavs] # Độ dài gốc của từng waveform\n",
        "    maxlen = max(lengths) # Độ dài lớn nhất trong batch\n",
        "    padded = []\n",
        "    for w in wavs:\n",
        "        if len(w) < maxlen:\n",
        "            # Pad waveform nếu ngắn hơn maxlen\n",
        "            w = F.pad(w, (0, maxlen - len(w)))\n",
        "        padded.append(w.unsqueeze(0)) # Thêm chiều batch\n",
        "    audio = torch.cat(padded, dim=0)  # Nối các waveform đã pad thành một tensor [B, T]\n",
        "    labels = torch.tensor(labels, dtype=torch.long) # Chuyển nhãn thành tensor\n",
        "    return audio, labels, torch.tensor(lengths, dtype=torch.long), paths # Trả về batch\n",
        "\n",
        "# =========================\n",
        "# SL-WDEE Emotional Encoder\n",
        "# =========================\n",
        "class ContextualTransform(nn.Module):\n",
        "    \"\"\"\n",
        "    Biến đổi đặc trưng frame-by-frame thành đặc trưng có ngữ cảnh (từ t-L đến t+R).\n",
        "    Input:  [B, T, D] (Batch, Time, Dimension)\n",
        "    Output: [B, T, D*(L+R+1)]\n",
        "    \"\"\"\n",
        "    def __init__(self, left=5, right=5):\n",
        "        super().__init__()\n",
        "        self.l = left # Số frame ngữ cảnh bên trái\n",
        "        self.r = right # Số frame ngữ cảnh bên phải\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, D]\n",
        "        B, T, D = x.shape\n",
        "        pads = (self.l, self.r)  # Số lượng padding theo chiều thời gian T\n",
        "        # Pad tensor theo chiều thời gian bằng cách lặp lại giá trị ở biên (mode=\"replicate\")\n",
        "        x_pad = F.pad(x.transpose(1,2), pad=(self.l, self.r), mode=\"replicate\").transpose(1,2)  # [B, T+L+R, D]\n",
        "        ctx_list = []\n",
        "        # Trích xuất các dải frame ngữ cảnh\n",
        "        for offset in range(-self.l, self.r+1):\n",
        "            start = (self.l + offset)\n",
        "            end = start + T\n",
        "            ctx_list.append(x_pad[:, start:end, :])  # [B, T, D]\n",
        "        # Nối các dải ngữ cảnh lại theo chiều cuối cùng (dimension)\n",
        "        ctx = torch.cat(ctx_list, dim=-1)  # [B, T, D*(L+R+1)]\n",
        "        return ctx\n",
        "\n",
        "class EmotionalEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Mô-đun Emotional Encoder theo bài báo SL-WDEE:\n",
        "    Layer Normalization -> Contextual Transform -> Linear -> Sigmoid -> Linear -> Sigmoid.\n",
        "    Trả về đặc trưng theo từng frame (SL-WDEE_t) và đặc trưng mức utterance (pooling).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim, hidden_dim=512, out_dim=256, left=5, right=5):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(in_dim) # Layer Normalization\n",
        "        self.ctx = ContextualTransform(left, right) # Biến đổi ngữ cảnh\n",
        "        self.fc1 = nn.Linear(in_dim*(left+right+1), hidden_dim) # Lớp Linear thứ nhất\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_dim) # Lớp Linear thứ hai\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, D] (đặc trưng từ WavLM)\n",
        "        x = self.norm(x) # Áp dụng Layer Normalization\n",
        "        x = self.ctx(x)                 # Áp dụng biến đổi ngữ cảnh [B, T, D*11]\n",
        "        x = torch.sigmoid(self.fc1(x))  # Lớp Linear 1 + Sigmoid [B, T, H]\n",
        "        x = torch.sigmoid(self.fc2(x))  # Lớp Linear 2 + Sigmoid [B, T, out]\n",
        "        # Pooling mức Utterance (trung bình cộng qua chiều thời gian)\n",
        "        wdee_utt = x.mean(dim=1)       # [B, out]\n",
        "        return x, wdee_utt  # Trả về đặc trưng frame-level và utterance-level\n",
        "\n",
        "# =========================\n",
        "# Classifier (utterance level)\n",
        "# =========================\n",
        "class MLPClassifier(nn.Module):\n",
        "    # Bộ phân loại MLP đơn giản cho đặc trưng mức utterance\n",
        "    def __init__(self, in_dim=256, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 256),     # Lớp Linear 1\n",
        "            nn.ReLU(inplace=True),      # Hàm kích hoạt ReLU\n",
        "            nn.Dropout(0.2),            # Dropout để chống overfitting\n",
        "            nn.Linear(256, 128),        # Lớp Linear 2\n",
        "            nn.ReLU(inplace=True),      # Hàm kích hoạt ReLU\n",
        "            nn.Dropout(0.2),            # Dropout\n",
        "            nn.Linear(128, num_classes) # Lớp Linear cuối cùng ra số lớp\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # x: [B, in_dim] (đặc trưng mức utterance)\n",
        "        return self.net(x) # Trả về logits\n",
        "\n",
        "# =========================\n",
        "# SER Model (WavLM -> SL-WDEE -> Classifier)\n",
        "# =========================\n",
        "class SER_WavLM_WDEE(nn.Module):\n",
        "    # Mô hình nhận dạng cảm xúc giọng nói kết hợp WavLM và SL-WDEE\n",
        "    def __init__(self, wavlm_name=\"microsoft/wavlm-base-plus\",\n",
        "                 wdee_hidden=512, wdee_out=256, freeze_wavlm=True):\n",
        "        super().__init__()\n",
        "        # Tải mô hình WavLM từ Hugging Face Transformers\n",
        "        self.wavlm = AutoModel.from_pretrained(wavlm_name)\n",
        "        hidden = self.wavlm.config.hidden_size # Kích thước đặc trưng đầu ra của WavLM (768)\n",
        "        # Khởi tạo Emotional Encoder\n",
        "        self.encoder = EmotionalEncoder(in_dim=hidden, hidden_dim=wdee_hidden, out_dim=wdee_out)\n",
        "        # Khởi tạo bộ phân loại MLP\n",
        "        self.cls = MLPClassifier(in_dim=wdee_out, num_classes=6)\n",
        "        # Tùy chọn đóng băng (freeze) các tham số của WavLM\n",
        "        if freeze_wavlm:\n",
        "            for p in self.wavlm.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _extract_wavlm_features(self, wav_batch, lengths):\n",
        "        # Trích xuất đặc trưng từ WavLM (không tính gradient)\n",
        "        # wav_batch: [B, T] float32, đã chuẩn hoá [-1,1]\n",
        "        B, T = wav_batch.shape\n",
        "        lengths = lengths.to(wav_batch.device)    #to device\n",
        "        # Tạo attention_mask: 1 cho phần có dữ liệu gốc, 0 cho phần padding\n",
        "        attention_mask = (torch.arange(T, device=wav_batch.device)[None, :] < lengths[:, None]).long()\n",
        "        # Chạy WavLM\n",
        "        outputs = self.wavlm(input_values=wav_batch, attention_mask=attention_mask, output_hidden_states=False)\n",
        "        feats = outputs.last_hidden_state  # Lấy đặc trưng từ lớp cuối cùng [B, T', D] (T' là số frame sau WavLM)\n",
        "        return feats\n",
        "\n",
        "\n",
        "    def forward(self, wav_batch, lengths):\n",
        "          # Chạy forward pass của toàn bộ mô hình\n",
        "          feats = self._extract_wavlm_features(wav_batch, lengths)   # Trích xuất đặc trưng WavLM [B,T',D]\n",
        "          per_frame_wdee, utt_wdee = self.encoder(feats)              # Chạy qua Emotional Encoder [B,T',E], [B,E]\n",
        "          logits = self.cls(utt_wdee)                                 # Chạy qua bộ phân loại [B,6]\n",
        "          return logits, utt_wdee # Trả về logits dự đoán cảm xúc và đặc trưng mức utterance WDEE\n",
        "\n",
        "# =========================\n",
        "# Training / Evaluation\n",
        "# =========================\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    # Lớp cấu hình cho quá trình huấn luyện\n",
        "    data_root: str\n",
        "    batch_size: int = 8\n",
        "    epochs: int = 20\n",
        "    lr: float = 2e-4\n",
        "    freeze_wavlm: bool = True\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    wavlm_name: str = \"microsoft/wavlm-base-plus\"\n",
        "    wdee_hidden: int = 512\n",
        "    wdee_out: int = 256\n",
        "    sr: int = 16000\n",
        "    val_ratio: float = 0.1\n",
        "    test_ratio: float = 0.1\n",
        "    grad_clip: float = 1.0\n",
        "    mixed_precision: bool = True # Sử dụng mixed precision training để tăng tốc (nếu có GPU)\n",
        "\n",
        "def train_one_epoch(model, loader, optim, scaler, cfg):\n",
        "    # Hàm huấn luyện một epoch\n",
        "    model.train() # Đặt model ở chế độ train\n",
        "    total_loss, total, correct = 0.0, 0, 0\n",
        "    for wav, y, lengths, _ in tqdm(loader, desc=\"Train\", leave=False):\n",
        "        wav, y = wav.to(cfg.device), y.to(cfg.device) # Chuyển dữ liệu lên device\n",
        "        optim.zero_grad(set_to_none=True) # Reset gradient\n",
        "        if cfg.mixed_precision:\n",
        "            # Sử dụng mixed precision nếu bật và có GPU\n",
        "            with torch.cuda.amp.autocast(enabled=(cfg.device.startswith(\"cuda\"))):\n",
        "                logits, _ = model(wav, lengths) # Forward pass\n",
        "                loss = F.cross_entropy(logits, y) # Tính loss (Cross-Entropy)\n",
        "            scaler.scale(loss).backward() # Scale loss và backward\n",
        "            scaler.unscale_(optim) # Unscale gradient trước khi clip\n",
        "            if cfg.grad_clip is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip) # Clip gradient\n",
        "            scaler.step(optim) # Cập nhật tham số\n",
        "            scaler.update() # Cập nhật scaler\n",
        "        else:\n",
        "            # Huấn luyện thông thường (full precision)\n",
        "            logits, _ = model(wav, lengths)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            if cfg.grad_clip is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "            optim.step()\n",
        "\n",
        "        total_loss += float(loss.item()) * len(y) # Cộng dồn loss\n",
        "        pred = logits.argmax(dim=1) # Lấy dự đoán\n",
        "        correct += int((pred==y).sum().item()) # Đếm số lượng dự đoán đúng\n",
        "        total += len(y) # Tổng số mẫu trong batch\n",
        "    return total_loss/total, correct/total # Trả về loss và accuracy trung bình epoch\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, cfg):\n",
        "    # Hàm đánh giá mô hình (không tính gradient)\n",
        "    model.eval()\n",
        "    total_loss, total, correct = 0.0, 0, 0\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for wav, y, lengths, _ in tqdm(loader, desc=\"Eval\", leave=False):\n",
        "        wav, y = wav.to(cfg.device), y.to(cfg.device)\n",
        "        logits, _ = model(wav, lengths)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        total_loss += float(loss.item()) * len(y)\n",
        "\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += int((pred == y).sum().item())\n",
        "        total += len(y)\n",
        "\n",
        "        y_true += y.detach().cpu().tolist()\n",
        "        y_pred += pred.detach().cpu().tolist()\n",
        "\n",
        "    # UA, WA, Confusion Matrix\n",
        "    UA, WA, cm = compute_UA_WA(y_true, y_pred, n_classes=6)\n",
        "\n",
        "    # Precision / Recall / F1\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    weighted_f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    macro_precision = precision_score(y_true, y_pred, average=\"macro\")\n",
        "    weighted_precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    macro_recall = recall_score(y_true, y_pred, average=\"macro\")\n",
        "    weighted_recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "    # (tuỳ chọn) in luôn classification report dạng bảng\n",
        "    cls_report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[IDX2EMO[i] for i in range(6)],\n",
        "        digits=4\n",
        "    )\n",
        "\n",
        "    # Có thể in ra trong lúc evaluate (debug)\n",
        "    # print(cls_report)\n",
        "\n",
        "    # Trả thêm các metric mới\n",
        "    return (\n",
        "        total_loss / total,\n",
        "        correct / total,\n",
        "        UA,\n",
        "        WA,\n",
        "        cm,\n",
        "        macro_f1,\n",
        "        weighted_f1,\n",
        "        macro_precision,\n",
        "        weighted_precision,\n",
        "        macro_recall,\n",
        "        weighted_recall,\n",
        "        cls_report,\n",
        "    )\n",
        "\n",
        "def main():\n",
        "    # Hàm chính để chạy huấn luyện và đánh giá\n",
        "    set_deterministic() # Đặt seed\n",
        "    cfg = TrainConfig(\n",
        "        data_root=\"/kaggle/input/crema-d/cremad/AudioWAV\", # Đường dẫn đến thư mục audio\n",
        "        epochs=20,\n",
        "        batch_size=8,\n",
        "        lr=2e-4,\n",
        "        freeze_wavlm=True # Đóng băng WavLM ở giai đoạn đầu\n",
        "    )\n",
        "    print(cfg)\n",
        "\n",
        "    # Khởi tạo Dataset cho train, val, test\n",
        "    train_ds = CREMADataset(cfg.data_root, \"train\", sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "    val_ds   = CREMADataset(cfg.data_root, \"val\",   sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "    test_ds  = CREMADataset(cfg.data_root, \"test\",  sr=cfg.sr, val_ratio=cfg.val_ratio, test_ratio=cfg.test_ratio)\n",
        "\n",
        "    # Khởi tạo DataLoader\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False, num_workers=4, collate_fn=collate_batch, pin_memory=True)\n",
        "\n",
        "    # Khởi tạo mô hình\n",
        "    model = SER_WavLM_WDEE(\n",
        "        wavlm_name=cfg.wavlm_name,\n",
        "        wdee_hidden=cfg.wdee_hidden,\n",
        "        wdee_out=cfg.wdee_out,\n",
        "        freeze_wavlm=cfg.freeze_wavlm\n",
        "    ).to(cfg.device) # Chuyển model lên device\n",
        "\n",
        "    # Khởi tạo optimizer và scaler (cho mixed precision)\n",
        "    optim = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=cfg.lr)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(cfg.device.startswith(\"cuda\") and cfg.mixed_precision))\n",
        "\n",
        "    best_val_ua, best_state = -1.0, None\n",
        "    # Vòng lặp huấn luyện qua các epoch\n",
        "    for epoch in range(1, cfg.epochs+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optim, scaler, cfg) # Huấn luyện 1 epoch\n",
        "        (\n",
        "          val_loss,\n",
        "          val_acc,\n",
        "          val_UA,\n",
        "          val_WA,\n",
        "          _,\n",
        "          val_f1_macro,\n",
        "          val_f1_weighted,\n",
        "          val_prec_macro,\n",
        "          val_prec_weighted,\n",
        "          val_rec_macro,\n",
        "          val_rec_weighted,\n",
        "          _\n",
        "      ) = evaluate(model, val_loader, cfg)\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch:02d}] \"\n",
        "            f\"Train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "            f\"Val loss {val_loss:.4f} acc {val_acc:.4f} \"\n",
        "            f\"UA {val_UA:.4f} WA {val_WA:.4f} \"\n",
        "            f\"F1(macro) {val_f1_macro:.4f} F1(weighted) {val_f1_weighted:.4f}\"\n",
        "        )\n",
        "        # Lưu trạng thái mô hình nếu đạt UA tốt nhất trên tập validation\n",
        "        if val_UA > best_val_ua:\n",
        "            best_val_ua = val_UA\n",
        "            best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
        "\n",
        "    # Load lại trạng thái mô hình tốt nhất từ validation\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict({k:v.to(cfg.device) for k,v in best_state.items()})\n",
        "\n",
        "    # Đánh giá cuối cùng trên tập test\n",
        "    (\n",
        "          te_loss,\n",
        "          te_acc,\n",
        "          te_UA,\n",
        "          te_WA,\n",
        "          _,\n",
        "          te_f1_macro,\n",
        "          te_f1_weighted,\n",
        "          te_prec_macro,\n",
        "          te_prec_weighted,\n",
        "          te_rec_macro,\n",
        "          te_rec_weighted,\n",
        "          _\n",
        "      ) = evaluate(model, test_loader, cfg)\n",
        "    print(\"\\n=== TEST RESULTS (CREMA-D) ===\")\n",
        "    print(f\"Train loss {te_loss:.4f} acc {te_acc:.4f} | \"\n",
        "            f\"Val loss {val_loss:.4f} acc {val_acc:.4f} \"\n",
        "            f\"UA {te_UA:.4f} WA {te_WA:.4f} \"\n",
        "            f\"F1(macro) {te_f1_macro:.4f} F1(weighted) {te_f1_weighted:.4f}\")\n",
        "    # In ra confusion matrix có nhãn\n",
        "    # df_cm = pd.DataFrame(cm, index=[IDX2EMO[i] for i in range(6)], columns=[IDX2EMO[i] for i in range(6)])\n",
        "    # print(\"\\nConfusion matrix:\")\n",
        "    # print(df_cm)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main() # Chạy hàm main khi script được thực thi trực tiếp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 1. Install & imports\n",
        "# -------------------------\n",
        "!pip install -q librosa soundfile tensorflow scikit-learn"
      ],
      "metadata": {
        "id": "EXdYyPGpwHLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-tdS5tf7qPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8a7251f-3ec6-4116-b482-7f3bcb885722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7442 labeled files.\n",
            "Number of speakers: 91\n",
            "Samples per split:\n",
            "  Train: 5885\n",
            "  Val  : 737\n",
            "  Test : 820\n",
            "Extracting features (this may take a while...)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7442/7442 [19:46<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input feature shape (T, F): (108, 216)\n",
            "X raw shape: (7442, 108, 216)\n",
            "y shape: (7442,)\n",
            "Saved cached features to: /content/cremad_features\n",
            "Final feature shape (N, T, F): (7442, 108, 216)\n",
            "Final splits:\n",
            "  Train: (5885, 108, 216) (5885,)\n",
            "  Val  : (737, 108, 216) (737,)\n",
            "  Test : (820, 108, 216) (820,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_Ensemble\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_Ensemble\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m216\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_1D (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │  \u001b[38;5;34m1,190,150\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_BiLSTM          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │    \u001b[38;5;34m486,662\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ensemble_avg        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ CNN_1D[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mAverage\u001b[0m)           │                   │            │ CNN_BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_1D (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,190,150</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_BiLSTM          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">486,662</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ensemble_avg        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ CNN_1D[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)           │                   │            │ CNN_BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,676,812\u001b[0m (6.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,676,812</span> (6.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,674,508\u001b[0m (6.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,674,508</span> (6.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.3538 - loss: 1.6881 - val_accuracy: 0.3094 - val_loss: 1.7881 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.5239 - loss: 1.2520 - val_accuracy: 0.4627 - val_loss: 1.4112 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5884 - loss: 1.1180 - val_accuracy: 0.5142 - val_loss: 1.3418 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6425 - loss: 0.9750 - val_accuracy: 0.4830 - val_loss: 1.3629 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7210 - loss: 0.8429 - val_accuracy: 0.5034 - val_loss: 1.3661 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7626 - loss: 0.7133 - val_accuracy: 0.5156 - val_loss: 1.3831 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8234 - loss: 0.5874 - val_accuracy: 0.4912 - val_loss: 1.5488 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8513 - loss: 0.5185 - val_accuracy: 0.5115 - val_loss: 1.6082 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8772 - loss: 0.4569 - val_accuracy: 0.5210 - val_loss: 1.6369 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8985 - loss: 0.4052 - val_accuracy: 0.5197 - val_loss: 1.6472 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9135 - loss: 0.3711 - val_accuracy: 0.4925 - val_loss: 1.7181 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9188 - loss: 0.3399 - val_accuracy: 0.5224 - val_loss: 1.6573 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9166 - loss: 0.3232 - val_accuracy: 0.5183 - val_loss: 1.8092 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9286 - loss: 0.2933 - val_accuracy: 0.5387 - val_loss: 1.8476 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9439 - loss: 0.2665 - val_accuracy: 0.5170 - val_loss: 1.8487 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9523 - loss: 0.2388 - val_accuracy: 0.5332 - val_loss: 1.9124 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.2336 - val_accuracy: 0.5495 - val_loss: 1.9700 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9554 - loss: 0.2150 - val_accuracy: 0.5495 - val_loss: 1.9617 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9588 - loss: 0.1989 - val_accuracy: 0.5292 - val_loss: 2.0379 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9643 - loss: 0.1877 - val_accuracy: 0.5590 - val_loss: 1.9439 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9568 - loss: 0.1931 - val_accuracy: 0.5129 - val_loss: 2.0376 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9549 - loss: 0.1929 - val_accuracy: 0.5278 - val_loss: 2.0459 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9534 - loss: 0.1988\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9534 - loss: 0.1987 - val_accuracy: 0.5577 - val_loss: 2.0556 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9597 - loss: 0.1855 - val_accuracy: 0.5441 - val_loss: 2.1053 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9737 - loss: 0.1330 - val_accuracy: 0.5645 - val_loss: 2.0745 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9772 - loss: 0.1231 - val_accuracy: 0.5767 - val_loss: 2.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.9765 - loss: 0.1095 - val_accuracy: 0.5902 - val_loss: 1.9589 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9752 - loss: 0.1031 - val_accuracy: 0.5577 - val_loss: 2.0116 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9789 - loss: 0.1004 - val_accuracy: 0.5617 - val_loss: 2.0302 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9828 - loss: 0.0912\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0911 - val_accuracy: 0.5726 - val_loss: 2.0504 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9837 - loss: 0.0856 - val_accuracy: 0.5658 - val_loss: 2.0214 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9835 - loss: 0.0796 - val_accuracy: 0.5672 - val_loss: 2.0820 - learning_rate: 2.5000e-04\n",
            "Epoch 32: early stopping\n",
            "Restoring model weights from the end of the best epoch: 27.\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "\n",
            "=== TEST RESULTS ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ANG       0.63      0.65      0.64       140\n",
            "         DIS       0.49      0.30      0.37       140\n",
            "         FEA       0.39      0.29      0.33       140\n",
            "         HAP       0.56      0.41      0.47       140\n",
            "         NEU       0.48      0.50      0.49       120\n",
            "         SAD       0.41      0.76      0.53       140\n",
            "\n",
            "    accuracy                           0.48       820\n",
            "   macro avg       0.49      0.48      0.47       820\n",
            "weighted avg       0.49      0.48      0.47       820\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 91  19  12  10   6   2]\n",
            " [ 11  42  14  11  10  52]\n",
            " [ 14   4  40  11  12  59]\n",
            " [ 19   8  24  57  17  15]\n",
            " [  9   6   7  11  60  27]\n",
            " [  1   7   5   1  20 106]]\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "#  CREMA-D SER pipeline (hand-crafted features + CNN/BiLSTM ensemble)\n",
        "#  with feature caching (save & reload X, y, splits)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization,\n",
        "                                     Flatten, Dense, Bidirectional, LSTM, Average)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# -------------------------\n",
        "# 2. Config\n",
        "# -------------------------\n",
        "DATA_DIR     = \"/root/.cache/kagglehub/datasets/akaiinu/crema-d/versions/1/cremad/AudioWAV\"\n",
        "SAMPLE_RATE  = 22050\n",
        "DURATION     = 2.5     # seconds (paper: 2.5s)\n",
        "OFFSET       = 0.6     # seconds (skip a bit of the start)\n",
        "FRAME_LENGTH = 2048\n",
        "HOP_LENGTH   = 512\n",
        "N_MFCC       = 40\n",
        "PITCH_STEPS  = 0.7\n",
        "NOISE_ALPHA  = 0.035\n",
        "\n",
        "RANDOM_SEED  = 42\n",
        "BATCH_SIZE   = 64\n",
        "EPOCHS       = 100\n",
        "\n",
        "# where to store cached features\n",
        "FEATURE_DIR  = \"/content/cremad_features\"\n",
        "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
        "X_PATH       = os.path.join(FEATURE_DIR, \"X_cremad.npy\")\n",
        "Y_PATH       = os.path.join(FEATURE_DIR, \"y_cremad.npy\")\n",
        "SPLIT_PATH   = os.path.join(FEATURE_DIR, \"splits_cremad.npy\")\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "EMOTION_MAP = {\n",
        "    \"ANG\": 0,\n",
        "    \"DIS\": 1,\n",
        "    \"FEA\": 2,\n",
        "    \"HAP\": 3,\n",
        "    \"NEU\": 4,\n",
        "    \"SAD\": 5\n",
        "}\n",
        "IDX2EMO = {v: k for k, v in EMOTION_MAP.items()}\n",
        "\n",
        "# -------------------------\n",
        "# 3. Scan CREMA-D file list\n",
        "#    Expect filenames like: 1001_DFA_ANG_XX.wav\n",
        "# -------------------------\n",
        "wav_paths = sorted(glob.glob(os.path.join(DATA_DIR, \"*.wav\")))\n",
        "if len(wav_paths) == 0:\n",
        "    raise RuntimeError(f\"No .wav found in {DATA_DIR}. Check your DATA_DIR path.\")\n",
        "\n",
        "records = []\n",
        "for p in wav_paths:\n",
        "    fname = os.path.basename(p)\n",
        "    parts = fname.split(\"_\")\n",
        "    # Example: 1001_DFA_ANG_XX.wav\n",
        "    try:\n",
        "        speaker_id = int(parts[0])\n",
        "        emotion_code = parts[2]\n",
        "    except Exception as e:\n",
        "        print(\"Skipping file with unexpected name format:\", fname, \"error:\", e)\n",
        "        continue\n",
        "\n",
        "    if emotion_code not in EMOTION_MAP:\n",
        "        continue\n",
        "\n",
        "    records.append({\n",
        "        \"path\": p,\n",
        "        \"speaker\": speaker_id,\n",
        "        \"emotion\": emotion_code\n",
        "    })\n",
        "\n",
        "print(f\"Found {len(records)} labeled files.\")\n",
        "\n",
        "# -------------------------\n",
        "# 4. Speaker-wise split (speaker-independent)\n",
        "#    80% train, 10% val, 10% test by speakers\n",
        "# -------------------------\n",
        "speakers = sorted(list({r[\"speaker\"] for r in records}))\n",
        "n_spk = len(speakers)\n",
        "print(\"Number of speakers:\", n_spk)\n",
        "\n",
        "train_end = int(0.8 * n_spk)\n",
        "val_end   = int(0.9 * n_spk)\n",
        "train_spk = set(speakers[:train_end])\n",
        "val_spk   = set(speakers[train_end:val_end])\n",
        "test_spk  = set(speakers[val_end:])\n",
        "\n",
        "for r in records:\n",
        "    if r[\"speaker\"] in train_spk:\n",
        "        r[\"split\"] = \"train\"\n",
        "    elif r[\"speaker\"] in val_spk:\n",
        "        r[\"split\"] = \"val\"\n",
        "    else:\n",
        "        r[\"split\"] = \"test\"\n",
        "\n",
        "print(\"Samples per split:\")\n",
        "print(\"  Train:\", sum(r[\"split\"] == \"train\" for r in records))\n",
        "print(\"  Val  :\", sum(r[\"split\"] == \"val\"   for r in records))\n",
        "print(\"  Test :\", sum(r[\"split\"] == \"test\"  for r in records))\n",
        "\n",
        "# -------------------------\n",
        "# 5. Audio loading & augmentation\n",
        "# -------------------------\n",
        "def load_segment(path, sr=SAMPLE_RATE, duration=DURATION, offset=OFFSET):\n",
        "    \"\"\"\n",
        "    Always return a segment of exactly `duration` seconds,\n",
        "    starting at `offset` seconds.\n",
        "    \"\"\"\n",
        "    y, _ = librosa.load(path, sr=sr)\n",
        "    seg_len = int(duration * sr)\n",
        "    start = int(offset * sr)\n",
        "\n",
        "    # Ensure we have at least start + seg_len samples\n",
        "    if len(y) < start + seg_len:\n",
        "        pad_len = start + seg_len - len(y)\n",
        "        y = np.pad(y, (0, pad_len))\n",
        "\n",
        "    # Now slice exactly [start : start + seg_len]\n",
        "    y = y[start:start + seg_len]\n",
        "\n",
        "    # Safety check: force exact length\n",
        "    if len(y) < seg_len:\n",
        "        y = np.pad(y, (0, seg_len - len(y)))\n",
        "    elif len(y) > seg_len:\n",
        "        y = y[:seg_len]\n",
        "\n",
        "    return y\n",
        "\n",
        "def add_noise(y, alpha=NOISE_ALPHA):\n",
        "    noise = np.random.randn(len(y))\n",
        "    return y + alpha * noise\n",
        "\n",
        "def pitch_shift(y, sr=SAMPLE_RATE, n_steps=PITCH_STEPS):\n",
        "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
        "\n",
        "# -------------------------\n",
        "# 6. Feature extraction (ZCR, RMSE, MFCC, Chroma STFT)\n",
        "# -------------------------\n",
        "def extract_single_features(y, sr=SAMPLE_RATE):\n",
        "    # Zero Crossing Rate\n",
        "    zcr = librosa.feature.zero_crossing_rate(\n",
        "        y, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH\n",
        "    )\n",
        "    # RMSE\n",
        "    rmse = librosa.feature.rms(\n",
        "        y=y, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH\n",
        "    )\n",
        "    # MFCC\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=y, sr=sr, n_mfcc=N_MFCC,\n",
        "        n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH\n",
        "    )\n",
        "    # Chroma STFT\n",
        "    stft = librosa.stft(y, n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
        "    chroma = librosa.feature.chroma_stft(\n",
        "        S=np.abs(stft), sr=sr\n",
        "    )\n",
        "\n",
        "    # zcr, rmse, mfcc, chroma each: (n_features, T)\n",
        "    feat = np.concatenate([zcr, rmse, mfcc, chroma], axis=0)  # (F, T)\n",
        "    return feat  # (F, T)\n",
        "\n",
        "def extract_augmented_features(path):\n",
        "    \"\"\"Return feature 2D array (F_total, T) after concatenating 4 augmentations.\"\"\"\n",
        "    y0 = load_segment(path)\n",
        "\n",
        "    y_noise = add_noise(y0)\n",
        "    y_pitch = pitch_shift(y0)\n",
        "    y_np    = add_noise(pitch_shift(y0))\n",
        "\n",
        "    feats = []\n",
        "    for y in (y0, y_noise, y_pitch, y_np):\n",
        "        f = extract_single_features(y)  # (F, T)\n",
        "        feats.append(f)\n",
        "\n",
        "    # Concatenate along feature axis\n",
        "    feat_cat = np.concatenate(feats, axis=0)  # (F_total, T)\n",
        "    return feat_cat\n",
        "\n",
        "# -------------------------\n",
        "# 7. Build or load dataset: X (N, T, F), y (N,), splits (N,)\n",
        "# -------------------------\n",
        "if os.path.exists(X_PATH) and os.path.exists(Y_PATH) and os.path.exists(SPLIT_PATH):\n",
        "    print(\"Loading cached features from disk...\")\n",
        "    X = np.load(X_PATH)\n",
        "    y = np.load(Y_PATH)\n",
        "    splits = np.load(SPLIT_PATH)\n",
        "    print(\"Loaded:\")\n",
        "    print(\"  X shape:\", X.shape)\n",
        "    print(\"  y shape:\", y.shape)\n",
        "else:\n",
        "    print(\"Extracting features (this may take a while...)\")\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    split_list = []\n",
        "\n",
        "    for r in tqdm(records):\n",
        "        feat_2d = extract_augmented_features(r[\"path\"])  # (F, T)\n",
        "        # Transpose to (T, F) for Keras Conv1D/LSTM\n",
        "        feat_2d = feat_2d.T\n",
        "        X_list.append(feat_2d)\n",
        "        y_list.append(EMOTION_MAP[r[\"emotion\"]])\n",
        "        split_list.append(r[\"split\"])\n",
        "\n",
        "    # Check shape consistency\n",
        "    shapes = {x.shape for x in X_list}\n",
        "    if len(shapes) != 1:\n",
        "        print(\"Warning: not all feature shapes are the same:\", shapes)\n",
        "    input_shape = X_list[0].shape  # (T, F)\n",
        "    print(\"Input feature shape (T, F):\", input_shape)\n",
        "\n",
        "    X = np.stack(X_list, axis=0)  # (N, T, F)\n",
        "    y = np.array(y_list)\n",
        "    splits = np.array(split_list)\n",
        "\n",
        "    print(\"X raw shape:\", X.shape)\n",
        "    print(\"y shape:\", y.shape)\n",
        "\n",
        "    # -------------------------\n",
        "    # 8. Feature scaling (StandardScaler on feature dimension)\n",
        "    # -------------------------\n",
        "    N, T, F = X.shape\n",
        "    X_2d = X.reshape(-1, F)   # (N*T, F)\n",
        "    scaler = StandardScaler()\n",
        "    X_2d = scaler.fit_transform(X_2d)\n",
        "    X = X_2d.reshape(N, T, F)\n",
        "\n",
        "    # save cached features\n",
        "    np.save(X_PATH, X)\n",
        "    np.save(Y_PATH, y)\n",
        "    np.save(SPLIT_PATH, splits)\n",
        "    print(\"Saved cached features to:\", FEATURE_DIR)\n",
        "\n",
        "# -------------------------\n",
        "# 9. Train/Val/Test split\n",
        "# -------------------------\n",
        "N, T, F = X.shape\n",
        "print(\"Final feature shape (N, T, F):\", X.shape)\n",
        "\n",
        "train_mask = splits == \"train\"\n",
        "val_mask   = splits == \"val\"\n",
        "test_mask  = splits == \"test\"\n",
        "\n",
        "X_train, y_train = X[train_mask], y[train_mask]\n",
        "X_val,   y_val   = X[val_mask],   y[val_mask]\n",
        "X_test,  y_test  = X[test_mask],  y[test_mask]\n",
        "\n",
        "print(\"Final splits:\")\n",
        "print(\"  Train:\", X_train.shape, y_train.shape)\n",
        "print(\"  Val  :\", X_val.shape,   y_val.shape)\n",
        "print(\"  Test :\", X_test.shape,  y_test.shape)\n",
        "\n",
        "num_classes = len(EMOTION_MAP)\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val_cat   = tf.keras.utils.to_categorical(y_val,   num_classes)\n",
        "y_test_cat  = tf.keras.utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "# -------------------------\n",
        "# 10. Define models: CNN & CNN+BiLSTM & Ensemble\n",
        "# -------------------------\n",
        "def build_cnn_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv1D(128, kernel_size=5, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv1D(256, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"CNN_1D\")\n",
        "    return model\n",
        "\n",
        "def build_cnn_bilstm_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv1D(128, kernel_size=5, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv1D(256, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Bi-LSTM\n",
        "    x = Bidirectional(LSTM(64, return_sequences=False))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"CNN_BiLSTM\")\n",
        "    return model\n",
        "\n",
        "input_shape = (T, F)\n",
        "cnn_model = build_cnn_model(input_shape, num_classes)\n",
        "bilstm_model = build_cnn_bilstm_model(input_shape, num_classes)\n",
        "\n",
        "# Ensemble: average the softmax outputs of both models\n",
        "ens_input = Input(shape=input_shape)\n",
        "cnn_out    = cnn_model(ens_input)\n",
        "bilstm_out = bilstm_model(ens_input)\n",
        "ens_out    = Average(name=\"ensemble_avg\")([cnn_out, bilstm_out])\n",
        "ensemble_model = Model(ens_input, ens_out, name=\"CNN_Ensemble\")\n",
        "\n",
        "# -------------------------\n",
        "# 11. Compile & train (with LR scheduler + early stopping)\n",
        "# -------------------------\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "ensemble_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor=\"val_accuracy\",\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(ensemble_model.summary())\n",
        "\n",
        "history = ensemble_model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[lr_scheduler, early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 12. Evaluation on test set\n",
        "# -------------------------\n",
        "y_prob = ensemble_model.predict(X_test)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(\"\\n=== TEST RESULTS ===\")\n",
        "print(classification_report(\n",
        "    y_test, y_pred,\n",
        "    target_names=[IDX2EMO[i] for i in range(num_classes)]\n",
        "))\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IHUBo4dspBN"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/cremad_features\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  CREMA-D SER pipeline (hand-crafted features + CNN/BiLSTM ensemble)\n",
        "#  Improved version:\n",
        "#   - Cache RAW features (no scaling)\n",
        "#   - Scale using ONLY train set (no data leakage)\n",
        "#   - Smaller, more regularized models to reduce overfitting\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization,\n",
        "                                     Flatten, Dense, Bidirectional, LSTM, Average)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# -------------------------\n",
        "# 2. Config\n",
        "# -------------------------\n",
        "DATA_DIR     = \"/root/.cache/kagglehub/datasets/akaiinu/crema-d/versions/1/cremad/AudioWAV\"\n",
        "SAMPLE_RATE  = 22050\n",
        "DURATION     = 2.5     # seconds (paper: 2.5s)\n",
        "OFFSET       = 0.6     # seconds (skip a bit of the start)\n",
        "FRAME_LENGTH = 2048\n",
        "HOP_LENGTH   = 512\n",
        "N_MFCC       = 40\n",
        "PITCH_STEPS  = 0.7\n",
        "NOISE_ALPHA  = 0.035\n",
        "\n",
        "RANDOM_SEED  = 42\n",
        "BATCH_SIZE   = 64\n",
        "EPOCHS       = 100\n",
        "\n",
        "# where to store cached RAW features\n",
        "FEATURE_DIR   = \"/content/cremad_features\"\n",
        "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
        "X_RAW_PATH    = os.path.join(FEATURE_DIR, \"X_raw_cremad.npy\")\n",
        "Y_PATH        = os.path.join(FEATURE_DIR, \"y_cremad.npy\")\n",
        "SPLIT_PATH    = os.path.join(FEATURE_DIR, \"splits_cremad.npy\")\n",
        "SCALER_PATH   = os.path.join(FEATURE_DIR, \"scaler_mean_var.npz\")  # optional: save scaler stats\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "EMOTION_MAP = {\n",
        "    \"ANG\": 0,\n",
        "    \"DIS\": 1,\n",
        "    \"FEA\": 2,\n",
        "    \"HAP\": 3,\n",
        "    \"NEU\": 4,\n",
        "    \"SAD\": 5\n",
        "}\n",
        "IDX2EMO = {v: k for k, v in EMOTION_MAP.items()}\n",
        "\n",
        "# -------------------------\n",
        "# 3. Scan CREMA-D file list\n",
        "#    Expect filenames like: 1001_DFA_ANG_XX.wav\n",
        "# -------------------------\n",
        "wav_paths = sorted(glob.glob(os.path.join(DATA_DIR, \"*.wav\")))\n",
        "if len(wav_paths) == 0:\n",
        "    raise RuntimeError(f\"No .wav found in {DATA_DIR}. Check your DATA_DIR path.\")\n",
        "\n",
        "records = []\n",
        "for p in wav_paths:\n",
        "    fname = os.path.basename(p)\n",
        "    parts = fname.split(\"_\")\n",
        "    # Example: 1001_DFA_ANG_XX.wav\n",
        "    try:\n",
        "        speaker_id = int(parts[0])\n",
        "        emotion_code = parts[2]\n",
        "    except Exception as e:\n",
        "        print(\"Skipping file with unexpected name format:\", fname, \"error:\", e)\n",
        "        continue\n",
        "\n",
        "    if emotion_code not in EMOTION_MAP:\n",
        "        continue\n",
        "\n",
        "    records.append({\n",
        "        \"path\": p,\n",
        "        \"speaker\": speaker_id,\n",
        "        \"emotion\": emotion_code\n",
        "    })\n",
        "\n",
        "print(f\"Found {len(records)} labeled files.\")\n",
        "\n",
        "# -------------------------\n",
        "# 4. Speaker-wise split (speaker-independent)\n",
        "#    80% train, 10% val, 10% test by speakers\n",
        "# -------------------------\n",
        "speakers = sorted(list({r[\"speaker\"] for r in records}))\n",
        "n_spk = len(speakers)\n",
        "print(\"Number of speakers:\", n_spk)\n",
        "\n",
        "train_end = int(0.8 * n_spk)\n",
        "val_end   = int(0.9 * n_spk)\n",
        "train_spk = set(speakers[:train_end])\n",
        "val_spk   = set(speakers[train_end:val_end])\n",
        "test_spk  = set(speakers[val_end:])\n",
        "\n",
        "for r in records:\n",
        "    if r[\"speaker\"] in train_spk:\n",
        "        r[\"split\"] = \"train\"\n",
        "    elif r[\"speaker\"] in val_spk:\n",
        "        r[\"split\"] = \"val\"\n",
        "    else:\n",
        "        r[\"split\"] = \"test\"\n",
        "\n",
        "print(\"Samples per split:\")\n",
        "print(\"  Train:\", sum(r[\"split\"] == \"train\" for r in records))\n",
        "print(\"  Val  :\", sum(r[\"split\"] == \"val\"   for r in records))\n",
        "print(\"  Test :\", sum(r[\"split\"] == \"test\"  for r in records))\n",
        "\n",
        "# -------------------------\n",
        "# 5. Audio loading & augmentation\n",
        "# -------------------------\n",
        "def load_segment(path, sr=SAMPLE_RATE, duration=DURATION, offset=OFFSET):\n",
        "    \"\"\"\n",
        "    Always return a segment of exactly `duration` seconds,\n",
        "    starting at `offset` seconds.\n",
        "    \"\"\"\n",
        "    y, _ = librosa.load(path, sr=sr)\n",
        "    seg_len = int(duration * sr)\n",
        "    start = int(offset * sr)\n",
        "\n",
        "    # Ensure we have at least start + seg_len samples\n",
        "    if len(y) < start + seg_len:\n",
        "        pad_len = start + seg_len - len(y)\n",
        "        y = np.pad(y, (0, pad_len))\n",
        "\n",
        "    # Now slice exactly [start : start + seg_len]\n",
        "    y = y[start:start + seg_len]\n",
        "\n",
        "    # Safety check: force exact length\n",
        "    if len(y) < seg_len:\n",
        "        y = np.pad(y, (0, seg_len - len(y)))\n",
        "    elif len(y) > seg_len:\n",
        "        y = y[:seg_len]\n",
        "\n",
        "    return y\n",
        "\n",
        "def add_noise(y, alpha=NOISE_ALPHA):\n",
        "    noise = np.random.randn(len(y))\n",
        "    return y + alpha * noise\n",
        "\n",
        "def pitch_shift(y, sr=SAMPLE_RATE, n_steps=PITCH_STEPS):\n",
        "    return librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
        "\n",
        "# -------------------------\n",
        "# 6. Feature extraction (ZCR, RMSE, MFCC, Chroma STFT)\n",
        "# -------------------------\n",
        "def extract_single_features(y, sr=SAMPLE_RATE):\n",
        "    # Zero Crossing Rate\n",
        "    zcr = librosa.feature.zero_crossing_rate(\n",
        "        y, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH\n",
        "    )\n",
        "    # RMSE\n",
        "    rmse = librosa.feature.rms(\n",
        "        y=y, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH\n",
        "    )\n",
        "    # MFCC\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=y, sr=sr, n_mfcc=N_MFCC,\n",
        "        n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH\n",
        "    )\n",
        "    # Chroma STFT\n",
        "    stft = librosa.stft(y, n_fft=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
        "    chroma = librosa.feature.chroma_stft(\n",
        "        S=np.abs(stft), sr=sr\n",
        "    )\n",
        "\n",
        "    # zcr, rmse, mfcc, chroma each: (n_features, T)\n",
        "    feat = np.concatenate([zcr, rmse, mfcc, chroma], axis=0)  # (F, T)\n",
        "    return feat  # (F, T)\n",
        "\n",
        "def extract_augmented_features(path):\n",
        "    \"\"\"Return feature 2D array (F_total, T) after concatenating 4 augmentations.\"\"\"\n",
        "    y0 = load_segment(path)\n",
        "\n",
        "    y_noise = add_noise(y0)\n",
        "    y_pitch = pitch_shift(y0)\n",
        "    y_np    = add_noise(pitch_shift(y0))\n",
        "\n",
        "    feats = []\n",
        "    for y in (y0, y_noise, y_pitch, y_np):\n",
        "        f = extract_single_features(y)  # (F, T)\n",
        "        feats.append(f)\n",
        "\n",
        "    # Concatenate along feature axis\n",
        "    feat_cat = np.concatenate(feats, axis=0)  # (F_total, T)\n",
        "    return feat_cat\n",
        "\n",
        "# -------------------------\n",
        "# 7. Build or load RAW dataset: X_raw (N, T, F), y (N,), splits (N,)\n",
        "# -------------------------\n",
        "X_RAW_PATH=\"/content/cremad_features/X_cremad.npy\"\n",
        "Y_PATH=\"/content/cremad_features/y_cremad.npy\"\n",
        "SPLIT_PATH=\"/content/cremad_features/splits_cremad.npy\"\n",
        "if os.path.exists(X_RAW_PATH) and os.path.exists(Y_PATH) and os.path.exists(SPLIT_PATH):\n",
        "    print(\"Loading cached RAW features from disk...\")\n",
        "    X_raw = np.load(X_RAW_PATH)\n",
        "    y = np.load(Y_PATH)\n",
        "    splits = np.load(SPLIT_PATH)\n",
        "    print(\"Loaded RAW:\")\n",
        "    print(\"  X_raw shape:\", X_raw.shape)\n",
        "    print(\"  y shape    :\", y.shape)\n",
        "else:\n",
        "    print(\"Extracting RAW features (this may take a while...)\")\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    split_list = []\n",
        "\n",
        "    for r in tqdm(records):\n",
        "        feat_2d = extract_augmented_features(r[\"path\"])  # (F, T)\n",
        "        # Transpose to (T, F) for Keras Conv1D/LSTM\n",
        "        feat_2d = feat_2d.T\n",
        "        X_list.append(feat_2d)\n",
        "        y_list.append(EMOTION_MAP[r[\"emotion\"]])\n",
        "        split_list.append(r[\"split\"])\n",
        "\n",
        "    shapes = {x.shape for x in X_list}\n",
        "    if len(shapes) != 1:\n",
        "        print(\"Warning: not all feature shapes are the same:\", shapes)\n",
        "    input_shape = X_list[0].shape  # (T, F)\n",
        "    print(\"Input RAW feature shape (T, F):\", input_shape)\n",
        "\n",
        "    X_raw = np.stack(X_list, axis=0)  # (N, T, F)\n",
        "    y = np.array(y_list)\n",
        "    splits = np.array(split_list)\n",
        "\n",
        "    print(\"X_raw shape:\", X_raw.shape)\n",
        "    print(\"y shape    :\", y.shape)\n",
        "\n",
        "    # Save RAW features only (no scaling)\n",
        "    np.save(X_RAW_PATH, X_raw)\n",
        "    np.save(Y_PATH, y)\n",
        "    np.save(SPLIT_PATH, splits)\n",
        "    print(\"Saved RAW features to:\", FEATURE_DIR)\n",
        "\n",
        "# -------------------------\n",
        "# 8. Train/Val/Test split + scaling (ONLY on train)\n",
        "# -------------------------\n",
        "N, T, F = X_raw.shape\n",
        "print(\"RAW feature shape (N, T, F):\", X_raw.shape)\n",
        "\n",
        "train_mask = splits == \"train\"\n",
        "val_mask   = splits == \"val\"\n",
        "test_mask  = splits == \"test\"\n",
        "\n",
        "X_train_raw, y_train = X_raw[train_mask], y[train_mask]\n",
        "X_val_raw,   y_val   = X_raw[val_mask],   y[val_mask]\n",
        "X_test_raw,  y_test  = X_raw[test_mask],  y[test_mask]\n",
        "\n",
        "print(\"RAW splits:\")\n",
        "print(\"  Train:\", X_train_raw.shape, y_train.shape)\n",
        "print(\"  Val  :\", X_val_raw.shape,   y_val.shape)\n",
        "print(\"  Test :\", X_test_raw.shape,  y_test.shape)\n",
        "\n",
        "# Fit scaler on TRAIN only (no leakage)\n",
        "scaler = StandardScaler()\n",
        "X_train_2d = X_train_raw.reshape(-1, F)\n",
        "scaler.fit(X_train_2d)\n",
        "\n",
        "# Optionally save scaler stats\n",
        "np.savez(SCALER_PATH, mean=scaler.mean_, var=scaler.var_)\n",
        "\n",
        "# Apply scaling\n",
        "X_train = scaler.transform(X_train_raw.reshape(-1, F)).reshape(X_train_raw.shape)\n",
        "X_val   = scaler.transform(X_val_raw.reshape(-1, F)).reshape(X_val_raw.shape)\n",
        "X_test  = scaler.transform(X_test_raw.reshape(-1, F)).reshape(X_test_raw.shape)\n",
        "\n",
        "print(\"Scaled splits:\")\n",
        "print(\"  Train:\", X_train.shape)\n",
        "print(\"  Val  :\", X_val.shape)\n",
        "print(\"  Test :\", X_test.shape)\n",
        "\n",
        "num_classes = len(EMOTION_MAP)\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val_cat   = tf.keras.utils.to_categorical(y_val,   num_classes)\n",
        "y_test_cat  = tf.keras.utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "# -------------------------\n",
        "# 9. Define models: smaller + more regularization\n",
        "# -------------------------\n",
        "def build_cnn_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\",\n",
        "               kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Conv1D(128, kernel_size=5, padding=\"same\", activation=\"relu\",\n",
        "               kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"CNN_1D_small\")\n",
        "    return model\n",
        "\n",
        "def build_cnn_bilstm_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\",\n",
        "               kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Conv1D(128, kernel_size=5, padding=\"same\", activation=\"relu\",\n",
        "               kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    # Bi-LSTM\n",
        "    x = Bidirectional(LSTM(32, return_sequences=False,\n",
        "                           kernel_regularizer=l2(1e-4)))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Dense(128, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"CNN_BiLSTM_small\")\n",
        "    return model\n",
        "\n",
        "input_shape = (T, F)\n",
        "cnn_model = build_cnn_model(input_shape, num_classes)\n",
        "bilstm_model = build_cnn_bilstm_model(input_shape, num_classes)\n",
        "\n",
        "# Ensemble: average the softmax outputs of both models\n",
        "ens_input   = Input(shape=input_shape)\n",
        "cnn_out     = cnn_model(ens_input)\n",
        "bilstm_out  = bilstm_model(ens_input)\n",
        "ens_out     = Average(name=\"ensemble_avg\")([cnn_out, bilstm_out])\n",
        "ensemble_model = Model(ens_input, ens_out, name=\"CNN_Ensemble\")\n",
        "\n",
        "# -------------------------\n",
        "# 10. Compile & train (with LR scheduler + early stopping + checkpoint)\n",
        "# -------------------------\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "ensemble_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor=\"val_accuracy\",\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=7,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=os.path.join(FEATURE_DIR, \"best_ensemble.h5\"),\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode=\"max\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(ensemble_model.summary())\n",
        "\n",
        "history = ensemble_model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[lr_scheduler, early_stop, checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 11. Evaluation on test set\n",
        "# -------------------------\n",
        "y_prob = ensemble_model.predict(X_test)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(\"\\n=== TEST RESULTS (speaker-independent) ===\")\n",
        "print(classification_report(\n",
        "    y_test, y_pred,\n",
        "    target_names=[IDX2EMO[i] for i in range(num_classes)]\n",
        "))\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LVPjND8cDIpr",
        "outputId": "c1918a5a-350b-49e4-a13b-7d8ad19a0e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7442 labeled files.\n",
            "Number of speakers: 91\n",
            "Samples per split:\n",
            "  Train: 5885\n",
            "  Val  : 737\n",
            "  Test : 820\n",
            "Loading cached RAW features from disk...\n",
            "Loaded RAW:\n",
            "  X_raw shape: (7442, 108, 216)\n",
            "  y shape    : (7442,)\n",
            "RAW feature shape (N, T, F): (7442, 108, 216)\n",
            "RAW splits:\n",
            "  Train: (5885, 108, 216) (5885,)\n",
            "  Val  : (737, 108, 216) (737,)\n",
            "  Test : (820, 108, 216) (820,)\n",
            "Scaled splits:\n",
            "  Train: (5885, 108, 216)\n",
            "  Val  : (737, 108, 216)\n",
            "  Test : (820, 108, 216)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_Ensemble\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_Ensemble\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m216\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_1D_small        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │    \u001b[38;5;34m554,822\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_BiLSTM_small    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │    \u001b[38;5;34m162,118\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ensemble_avg        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ CNN_1D_small[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mAverage\u001b[0m)           │                   │            │ CNN_BiLSTM_small… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_1D_small        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">554,822</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ CNN_BiLSTM_small    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">162,118</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ensemble_avg        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ CNN_1D_small[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)           │                   │            │ CNN_BiLSTM_small… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m716,940\u001b[0m (2.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">716,940</span> (2.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m715,532\u001b[0m (2.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">715,532</span> (2.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2934 - loss: 2.0218\n",
            "Epoch 1: val_accuracy improved from -inf to 0.37042, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.2939 - loss: 2.0205 - val_accuracy: 0.3704 - val_loss: 1.6665 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4253 - loss: 1.6308\n",
            "Epoch 2: val_accuracy improved from 0.37042 to 0.43691, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.4256 - loss: 1.6301 - val_accuracy: 0.4369 - val_loss: 1.4966 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4620 - loss: 1.5145\n",
            "Epoch 3: val_accuracy improved from 0.43691 to 0.48982, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.4620 - loss: 1.5146 - val_accuracy: 0.4898 - val_loss: 1.4494 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4862 - loss: 1.4616\n",
            "Epoch 4: val_accuracy did not improve from 0.48982\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.4864 - loss: 1.4611 - val_accuracy: 0.4830 - val_loss: 1.4375 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5313 - loss: 1.3724\n",
            "Epoch 5: val_accuracy did not improve from 0.48982\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5312 - loss: 1.3725 - val_accuracy: 0.4885 - val_loss: 1.4696 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5434 - loss: 1.3447\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.48982\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5435 - loss: 1.3445 - val_accuracy: 0.4763 - val_loss: 1.4327 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5729 - loss: 1.2811\n",
            "Epoch 7: val_accuracy did not improve from 0.48982\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5730 - loss: 1.2807 - val_accuracy: 0.4722 - val_loss: 1.4487 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5936 - loss: 1.2265\n",
            "Epoch 8: val_accuracy improved from 0.48982 to 0.50068, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5936 - loss: 1.2262 - val_accuracy: 0.5007 - val_loss: 1.4312 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6090 - loss: 1.1937\n",
            "Epoch 9: val_accuracy did not improve from 0.50068\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6090 - loss: 1.1935 - val_accuracy: 0.4790 - val_loss: 1.4579 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6148 - loss: 1.1756\n",
            "Epoch 10: val_accuracy did not improve from 0.50068\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.6149 - loss: 1.1754 - val_accuracy: 0.5007 - val_loss: 1.4567 - learning_rate: 5.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6414 - loss: 1.1317\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.50068\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.6415 - loss: 1.1316 - val_accuracy: 0.4885 - val_loss: 1.4512 - learning_rate: 5.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6444 - loss: 1.1119\n",
            "Epoch 12: val_accuracy did not improve from 0.50068\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6448 - loss: 1.1112 - val_accuracy: 0.4939 - val_loss: 1.4672 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6598 - loss: 1.0820\n",
            "Epoch 13: val_accuracy did not improve from 0.50068\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6600 - loss: 1.0814 - val_accuracy: 0.4966 - val_loss: 1.4701 - learning_rate: 2.5000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6775 - loss: 1.0432\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.50068\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6774 - loss: 1.0430 - val_accuracy: 0.4953 - val_loss: 1.4914 - learning_rate: 2.5000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6791 - loss: 1.0351\n",
            "Epoch 15: val_accuracy improved from 0.50068 to 0.50204, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.6792 - loss: 1.0348 - val_accuracy: 0.5020 - val_loss: 1.4961 - learning_rate: 1.2500e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6945 - loss: 1.0087\n",
            "Epoch 16: val_accuracy did not improve from 0.50204\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.6945 - loss: 1.0085 - val_accuracy: 0.5007 - val_loss: 1.5027 - learning_rate: 1.2500e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6917 - loss: 0.9933\n",
            "Epoch 17: val_accuracy improved from 0.50204 to 0.50611, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.6917 - loss: 0.9932 - val_accuracy: 0.5061 - val_loss: 1.5028 - learning_rate: 1.2500e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6979 - loss: 0.9910\n",
            "Epoch 18: val_accuracy improved from 0.50611 to 0.50746, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.6979 - loss: 0.9909 - val_accuracy: 0.5075 - val_loss: 1.5039 - learning_rate: 1.2500e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6999 - loss: 0.9719\n",
            "Epoch 19: val_accuracy improved from 0.50746 to 0.51560, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7001 - loss: 0.9717 - val_accuracy: 0.5156 - val_loss: 1.5116 - learning_rate: 1.2500e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7086 - loss: 0.9674\n",
            "Epoch 20: val_accuracy improved from 0.51560 to 0.52239, saving model to /content/cremad_features/best_ensemble.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7087 - loss: 0.9673 - val_accuracy: 0.5224 - val_loss: 1.5125 - learning_rate: 1.2500e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7113 - loss: 0.9538\n",
            "Epoch 21: val_accuracy did not improve from 0.52239\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7113 - loss: 0.9536 - val_accuracy: 0.5007 - val_loss: 1.5302 - learning_rate: 1.2500e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7235 - loss: 0.9367\n",
            "Epoch 22: val_accuracy did not improve from 0.52239\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7235 - loss: 0.9366 - val_accuracy: 0.5075 - val_loss: 1.5230 - learning_rate: 1.2500e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m91/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7104 - loss: 0.9361\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.52239\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.7105 - loss: 0.9360 - val_accuracy: 0.5061 - val_loss: 1.5103 - learning_rate: 1.2500e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7199 - loss: 0.9360\n",
            "Epoch 24: val_accuracy did not improve from 0.52239\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7200 - loss: 0.9358 - val_accuracy: 0.5020 - val_loss: 1.5468 - learning_rate: 6.2500e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7226 - loss: 0.9284\n",
            "Epoch 25: val_accuracy did not improve from 0.52239\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7226 - loss: 0.9283 - val_accuracy: 0.5075 - val_loss: 1.5487 - learning_rate: 6.2500e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7385 - loss: 0.9079\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.52239\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7385 - loss: 0.9078 - val_accuracy: 0.5102 - val_loss: 1.5285 - learning_rate: 6.2500e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7297 - loss: 0.9118\n",
            "Epoch 27: val_accuracy did not improve from 0.52239\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7298 - loss: 0.9112 - val_accuracy: 0.5142 - val_loss: 1.5389 - learning_rate: 3.1250e-05\n",
            "Epoch 27: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "\n",
            "=== TEST RESULTS (speaker-independent) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ANG       0.82      0.49      0.61       140\n",
            "         DIS       0.51      0.25      0.34       140\n",
            "         FEA       0.34      0.24      0.28       140\n",
            "         HAP       0.51      0.29      0.37       140\n",
            "         NEU       0.38      0.58      0.46       120\n",
            "         SAD       0.37      0.82      0.51       140\n",
            "\n",
            "    accuracy                           0.44       820\n",
            "   macro avg       0.49      0.44      0.43       820\n",
            "weighted avg       0.49      0.44      0.43       820\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 68  21  14  16  17   4]\n",
            " [  1  35  12   6  23  63]\n",
            " [  5   1  34  11  13  76]\n",
            " [  9   6  24  40  40  21]\n",
            " [  0   4  12   4  70  30]\n",
            " [  0   1   4   1  19 115]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}